{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-27T19:51:29.027612Z","iopub.status.busy":"2023-03-27T19:51:29.026845Z","iopub.status.idle":"2023-03-27T19:51:31.263242Z","shell.execute_reply":"2023-03-27T19:51:31.261820Z","shell.execute_reply.started":"2023-03-27T19:51:29.027567Z"},"trusted":true},"outputs":[],"source":["# ! git clone https://github.com/proshian/DNN_course_ITMO_2022.git\n","# %cd /kaggle/working/DNN_course_ITMO_2022\n","# !git checkout reorganisation_and_batchnorm_fix"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-03-28T08:09:44.403017Z","iopub.status.busy":"2023-03-28T08:09:44.402165Z","iopub.status.idle":"2023-03-28T08:09:44.411918Z","shell.execute_reply":"2023-03-28T08:09:44.410784Z","shell.execute_reply.started":"2023-03-28T08:09:44.402933Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/working/DNN_course_ITMO_2022\n"]}],"source":["# %cd /kaggle/working/DNN_course_ITMO_2022"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-03-27T23:28:32.135830Z","iopub.status.busy":"2023-03-27T23:28:32.135441Z","iopub.status.idle":"2023-03-27T23:28:32.403934Z","shell.execute_reply":"2023-03-27T23:28:32.402937Z","shell.execute_reply.started":"2023-03-27T23:28:32.135797Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["c:\\Users\\SystemPoint\\Documents\\GitHub\\DNN_lab_1\n"]}],"source":["# move to project's root directory to make numpy_nn package accessable \n","%cd ..\n","\n","\n","# Another possible solution is appending to the sys.path\n","\n","# import sys\n","# import  os\n","# project_root = os.path.dirname(sys.path[0])\n","# if project_root not in sys.path:\n","#     sys.path.append(project_root)"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-03-28T08:12:20.741662Z","iopub.status.busy":"2023-03-28T08:12:20.741012Z","iopub.status.idle":"2023-03-28T08:12:20.787042Z","shell.execute_reply":"2023-03-28T08:12:20.785986Z","shell.execute_reply.started":"2023-03-28T08:12:20.741603Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import pickle\n","import os\n","from collections import Counter\n","\n","\n","import numpy as np\n","from keras.datasets import mnist\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","\n","\n","from numpy_nn.modules.np_nn import (\n","    FullyConnectedLayer,\n","    ReLULayer,\n","    SigmoidLayer,\n","    ReLULayer,\n","    AdamOptimizer,\n","    CrossEntropyLoss,\n","    LinearActivation,\n","    Sequential,\n","    Optimizer,\n","    SoftMaxLayer,\n","    GradientDescentOptimizer,\n","    CrossEntropyLossWithSoftMax,\n","    softmax,\n","    Conv2d,\n","    Flatten,\n","    BatchNormalization2d,\n",")\n","\n","# from numpy_nn.models.resnet_without_batchnorm import resnet101\n","\n","from numpy_nn.models.resnet import resnet101\n","\n","plt.gray()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-03-28T08:09:57.008588Z","iopub.status.busy":"2023-03-28T08:09:57.007340Z","iopub.status.idle":"2023-03-28T08:09:57.019103Z","shell.execute_reply":"2023-03-28T08:09:57.017578Z","shell.execute_reply.started":"2023-03-28T08:09:57.008514Z"},"trusted":true},"outputs":[],"source":["def one_hot(y: np.ndarray, n_classes: int):\n","    encoded = np.zeros((y.size, n_classes))\n","    encoded[np.arange(y.size), y] = 1\n","    return encoded\n","\n","def padding(X, pad):\n","    batch_size, channels, h, w = X.shape\n","    out = np.zeros((batch_size, channels, h + 2 * pad, w + 2 * pad))\n","    out[:, :, pad:pad + h, pad:pad + w] = X\n","    return out"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-03-28T08:09:57.022289Z","iopub.status.busy":"2023-03-28T08:09:57.021739Z","iopub.status.idle":"2023-03-28T08:09:58.427352Z","shell.execute_reply":"2023-03-28T08:09:58.425818Z","shell.execute_reply.started":"2023-03-28T08:09:57.022209Z"},"trusted":true},"outputs":[],"source":["((X_train, y_train), (X_test, y_test)) = mnist.load_data()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-03-28T08:09:58.430935Z","iopub.status.busy":"2023-03-28T08:09:58.430518Z","iopub.status.idle":"2023-03-28T08:09:58.451879Z","shell.execute_reply":"2023-03-28T08:09:58.450121Z","shell.execute_reply.started":"2023-03-28T08:09:58.430900Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0: 5923 1: 6742 2: 5958 3: 6131 4: 5842 5: 5421 6: 5918 7: 6265 8: 5851 9: 5949 \n","0: 980 1: 1135 2: 1032 3: 1010 4: 982 5: 892 6: 958 7: 1028 8: 974 9: 1009 "]}],"source":["y_train_value_counts = Counter(y_train)\n","y_test_value_counts = Counter(y_test)\n","\n","for key in range(10):\n","    print(f\"{key}: {y_train_value_counts[key]}\", end = ' ')\n","print()\n","for key in range(10):\n","    print(f\"{key}: {y_test_value_counts[key]}\", end = ' ')"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-03-28T08:09:58.455045Z","iopub.status.busy":"2023-03-28T08:09:58.453840Z","iopub.status.idle":"2023-03-28T08:09:59.449059Z","shell.execute_reply":"2023-03-28T08:09:59.447483Z","shell.execute_reply.started":"2023-03-28T08:09:58.454986Z"},"trusted":true},"outputs":[],"source":["X_train = padding(X_train.reshape(-1, 1, 28, 28), 2).astype(np.float32)\n","X_test = padding(X_test.reshape(-1, 1, 28, 28), 2).astype(np.float32)\n","y_train = one_hot(y_train, 10)\n","y_test = one_hot(y_test, 10)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-03-28T08:09:59.451296Z","iopub.status.busy":"2023-03-28T08:09:59.450732Z","iopub.status.idle":"2023-03-28T08:09:59.462029Z","shell.execute_reply":"2023-03-28T08:09:59.459727Z","shell.execute_reply.started":"2023-03-28T08:09:59.451215Z"},"trusted":true},"outputs":[{"data":{"text/plain":["((60000, 10), (60000, 1, 32, 32))"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["y_train.shape, X_train.shape"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-03-28T08:10:04.502887Z","iopub.status.busy":"2023-03-28T08:10:04.501398Z","iopub.status.idle":"2023-03-28T08:10:04.652468Z","shell.execute_reply":"2023-03-28T08:10:04.650402Z","shell.execute_reply.started":"2023-03-28T08:10:04.502830Z"},"trusted":true},"outputs":[],"source":["X_train = X_train/255\n","X_test = X_test/255"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-03-28T08:10:05.210632Z","iopub.status.busy":"2023-03-28T08:10:05.210146Z","iopub.status.idle":"2023-03-28T08:10:05.363828Z","shell.execute_reply":"2023-03-28T08:10:05.361803Z","shell.execute_reply.started":"2023-03-28T08:10:05.210591Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<matplotlib.image.AxesImage at 0x1984b2a7400>"]},"execution_count":9,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["plt.axis('off')\n","plt.title(f\"true label: {np.argmax(y_train[0])}\")\n","plt.imshow(X_train[0].reshape(32, 32))"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-03-28T08:10:33.837908Z","iopub.status.busy":"2023-03-28T08:10:33.837326Z","iopub.status.idle":"2023-03-28T08:10:33.857288Z","shell.execute_reply":"2023-03-28T08:10:33.856124Z","shell.execute_reply.started":"2023-03-28T08:10:33.837851Z"},"trusted":true},"outputs":[],"source":["# The history is calculated for the whole epoch in implementation below\n","\n","def train(model, X_train: np.ndarray, y_train: np.ndarray, X_test: np.ndarray, y_test: np.ndarray,\n","          optimizer: Optimizer, loss, epochs: int, batch_size: int, metric_names, epoch_history):\n","    \n","    for i in range(epochs):\n","        for phase in ['train', 'test']:\n","            if phase == 'train':\n","                model.train()\n","                X, y = X_train, y_train\n","            elif phase == 'test':\n","                model.eval()\n","                X, y = X_test, y_test\n","            \n","            print(phase)\n","            epoch_loss = 0\n","            \n","            all_true_y = []\n","            all_pred_y = []\n","            \n","            batch_pbar = tqdm(range(0, X.shape[0], batch_size))\n","            \n","            for j in batch_pbar:\n","                # print(f\"epoch {i} batch {j}\")\n","                X_b, y_b = X[j:j+batch_size], y[j:j+batch_size]\n","                y_pred = model.forward(X_b)\n","                loss_val = loss.forward(y_pred, y_b)\n","\n","                y_pred_label_b = np.argmax(y_pred, axis=1)\n","                y_true_label_b = np.argmax(y_b, axis=1)\n","                \n","                batch_results = {\n","                    'loss': loss_val,\n","                    'accuracy': np.mean(np.array(y_pred_label_b) == np.array(y_true_label_b)),\n","                    'f1_score': f1_score(y_pred_label_b, y_true_label_b, average='macro'),\n","                }\n","                \n","                all_pred_y.extend(y_pred_label_b)\n","                all_true_y.extend(y_true_label_b)\n","                epoch_loss += loss_val\n","\n","                if phase == 'train':\n","                    loss_gradient = loss.backward()\n","                    model.backward(loss_gradient)\n","                    optimizer.step()\n","                \n","                progress_string = \"batch: \"\n","                for metric_name in batch_results:\n","                    progress_string+=f\"{metric_name}: {batch_results[metric_name]:.2f}  \"\n","                batch_pbar.set_description(progress_string)\n","                \n","            epoch_history[phase]['accuracy'].append(np.mean(np.array(all_pred_y) == np.array(all_true_y)))\n","            epoch_history[phase]['f1_score'].append(f1_score(all_pred_y, all_true_y, average='macro'))\n","            epoch_history[phase]['loss'].append(epoch_loss)\n","            \n","            print(f\"epoch metrics: loss = {epoch_history[phase]['loss'][-1]:.4f}, \\\n","                accuracy = {epoch_history[phase]['accuracy'][-1]:.4f}, \\\n","                f score = {epoch_history[phase]['f1_score'][-1]:.4f}\")\n","            \n","            \n","            \n","            epoch_history_name = 'numpy_resnet_epoch_history.pickle'\n","\n","            with open(epoch_history_name, 'wb') as f:\n","                pickle.dump(epoch_history, f)\n","\n","            # with open(epoch_history_name, 'rb') as f:\n","            #     epoch_history = pickle.load(f)\n","            \n","            for layer in model.trainable_layers:\n","                layer.input_ = None\n","            \n","            model_file_name = 'numpy_resnet_1.pickle'\n","\n","            with open(model_file_name, 'wb') as f:\n","                pickle.dump(model, f)\n","            \n","            adam_name = './numpy_resnet_adam.pickle'\n","\n","            with open(adam_name, 'wb') as f:\n","                pickle.dump(optimizer, f)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-03-28T08:16:56.289699Z","iopub.status.busy":"2023-03-28T08:16:56.289206Z","iopub.status.idle":"2023-03-28T08:16:56.298091Z","shell.execute_reply":"2023-03-28T08:16:56.296571Z","shell.execute_reply.started":"2023-03-28T08:16:56.289662Z"},"trusted":true},"outputs":[],"source":["# ! Decided that probably torch  follows the best initialization\n","# practices which may lead to better performance\n","\n","def get_model_initialized_with_torch():\n","    model = resnet101(10, 1)\n","    \n","    from pytorch_nn.models.resnet import resnet101 as resnet101_torch\n","\n","    torch_resnet = resnet101_torch(10, 1)\n","\n","    model.clone_weights_from_torch(torch_resnet)\n","    \n","    return model"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-03-28T08:53:15.996329Z","iopub.status.busy":"2023-03-28T08:53:15.995005Z","iopub.status.idle":"2023-03-28T08:53:22.676971Z","shell.execute_reply":"2023-03-28T08:53:22.674461Z","shell.execute_reply.started":"2023-03-28T08:53:15.996262Z"},"trusted":true},"outputs":[],"source":["model_init_file_name = r\"numpy_resnet_init.pickle\"\n","\n","model_file_name = 'numpy_resnet_1.pickle'\n","history_name = 'numpy_resnet_epoch_history.pickle'\n","adam_name = 'numpy_resnet_adam.pickle'\n","\n","\n","loss = CrossEntropyLossWithSoftMax()\n","metric_names = ['loss', 'accuracy', 'f1_score']\n","\n","if os.path.exists(model_file_name) and os.path.exists(adam_name) and os.path.exists(history_name):\n","    with open(model_file_name, 'rb') as f:\n","        model = pickle.load(f)\n","    with open(history_name, 'rb') as f:\n","        epoch_history = pickle.load(f)\n","    with open(adam_name, 'rb') as f:\n","        optimizer = pickle.load(f)\n","    \n","    optimizer.trainable_layers = model.trainable_layers\n","    \n","    for layer in optimizer.trainable_layers:\n","        for _, _, id in layer.get_parameters_and_gradients_and_ids():\n","            if not id in optimizer.m.keys():\n","                print(\"problem\")\n","else:\n","    if not os.path.exists(model_init_file_name):\n","        model = get_model_initialized_with_torch()\n","        with open(model_init_file_name, 'wb') as f:\n","            pickle.dump(model, f)\n","    else:\n","        with open(model_init_file_name, 'rb') as f:\n","            model = pickle.load(f)\n","            \n","    optimizer = AdamOptimizer(model.trainable_layers, learning_rate = 1e-3)\n","    epoch_history = {phase_name: {metric_name: [] for metric_name in metric_names} for phase_name in ['train', 'test']}\n","\n","model.eval()"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-03-28T08:53:22.680701Z","iopub.status.busy":"2023-03-28T08:53:22.680279Z","iopub.status.idle":"2023-03-28T08:53:23.841425Z","shell.execute_reply":"2023-03-28T08:53:23.839680Z","shell.execute_reply.started":"2023-03-28T08:53:22.680665Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["171\t./numpy_resnet_init.pickle\n"]}],"source":["# Model weights over 5 Gb due to saving of converted inputs in Conv2d\n","!du --block-size=1MB ./numpy_resnet_init.pickle"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["epochs = 3\n","\n","batch_size = 64\n","train(\n","    model, X_train, y_train,\n","    X_test, y_test,\n","    optimizer, loss, epochs, batch_size,\n","    metric_names, epoch_history)\n","model.eval()"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-03-28T08:39:33.324869Z","iopub.status.busy":"2023-03-28T08:39:33.324395Z","iopub.status.idle":"2023-03-28T08:39:54.633983Z","shell.execute_reply":"2023-03-28T08:39:54.632568Z","shell.execute_reply.started":"2023-03-28T08:39:33.324830Z"},"trusted":true},"outputs":[],"source":["# epochs = 1\n","# batch_size = 1\n","# history = train(\n","#     model, X_train[0:3], y_train[0:3],\n","#     X_test[0:3], y_test[0:3],\n","#     optimizer, loss, epochs, batch_size, metric_names, epoch_history)\n","\n","\n","# epochs = 2\n","# batch_size = 32\n","# dataset_percent = 100\n","# history = train(\n","#     model, X_train[0:640*dataset_percent], y_train[0:640*dataset_percent],\n","#     X_test[0:100*dataset_percent], y_test[0:100*dataset_percent],\n","#     optimizer, loss, epochs, batch_size, metric_names, epoch_history)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for layer in model.trainable_layers:\n","    layer.input_ = None"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"trusted":true},"outputs":[],"source":["print(epoch_history)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def plot_history(history_list):\n","    history1 = history_list[0]\n","    phases = list(history1.keys())\n","    fig, axs = plt.subplots(len(phases), len(history1[phases[0]]))\n","\n","    fig.set_figheight(10)\n","    fig.set_figwidth(20)\n","\n","    for phase_index, phase in enumerate(phases):\n","        for key_index, (key, value) in enumerate(history1[phase].items()):\n","            for history in history_list:\n","                axs[phase_index][key_index].plot(history[phase][key])\n","            axs[phase_index][key_index].set_title(f\"{phase} {key}\")\n","    plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plot_history([epoch_history])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-23T09:31:22.068646Z","iopub.status.busy":"2023-01-23T09:31:22.068236Z","iopub.status.idle":"2023-01-23T09:31:22.077314Z","shell.execute_reply":"2023-01-23T09:31:22.076088Z","shell.execute_reply.started":"2023-01-23T09:31:22.068616Z"}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-23T09:31:22.079328Z","iopub.status.busy":"2023-01-23T09:31:22.078944Z","iopub.status.idle":"2023-01-23T09:31:22.093282Z","shell.execute_reply":"2023-01-23T09:31:22.092057Z","shell.execute_reply.started":"2023-01-23T09:31:22.079296Z"}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-23T09:31:22.782730Z","iopub.status.busy":"2023-01-23T09:31:22.782291Z","iopub.status.idle":"2023-01-23T09:31:22.788807Z","shell.execute_reply":"2023-01-23T09:31:22.787657Z","shell.execute_reply.started":"2023-01-23T09:31:22.782696Z"}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"trusted":true},"outputs":[],"source":["for i in range(5):\n","    probs_i = softmax(model.forward(X_train[i].reshape(1, 1, 32, 32)))\n","    plt.title(f\"true label: {np.argmax(y_train[i])}\\n predicted label: {np.argmax(probs_i)}\")\n","    plt.imshow(X_train[i].reshape(32, 32))\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for i in range(5):\n","    probs_i = softmax(model.forward(X_test[i].reshape(1, 1, 32, 32)))\n","    plt.title(f\"true label: {np.argmax(y_test[i])}\\n predicted label: {np.argmax(probs_i)}\")\n","    plt.imshow(X_test[i].reshape(32, 32))\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# Small CNN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["_, in_channels, height, width, = X_train.shape\n","out_channels = 32\n","kernel_size = 3\n","stride = 1\n","padding = 1\n","bias = True\n","\n","\n","batch_size = 64\n","epochs = 5\n","weights_data = []\n","\n","model_small_cnn = Sequential([\n","    Conv2d(in_channels, out_channels, kernel_size, stride, padding), ReLULayer(),\n","    # Conv2d(out_channels, out_channels, kernel_size, stride, padding), ReLULayer(),\n","    Flatten(), FullyConnectedLayer(height * width * out_channels, 10)])\n","# optimizer = GradientDescentOptimizer(model.trainable_layers, learning_rate = 1e-3)\n","optimizer_small_cnn = AdamOptimizer(model_small_cnn.trainable_layers, learning_rate = 1e-3)\n","loss = CrossEntropyLossWithSoftMax()\n","\n","metric_names = ['loss', 'accuracy', 'f1_score']\n","epoch_history_small_cnn = {phase_name: {metric_name: [] for metric_name in metric_names} for phase_name in ['train', 'test']}\n","# epoch_history_small_cnn['experimant_name'] = 'small cnn'\n","\n","train(model_small_cnn, X_train, y_train, X_test, y_test, optimizer_small_cnn, loss, epochs, batch_size, metric_names, epoch_history_small_cnn)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_history([epoch_history_small_cnn])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train_torch = torch.from_numpy(X_train).float()\n","y_train_torch = torch.from_numpy(y_train)\n","\n","X_test_torch = torch.from_numpy(X_test).float()\n","y_test_torch = torch.from_numpy(y_test)\n","\n","def train_torch(model, X_train: torch.Tensor, y_train: torch.Tensor, X_test: torch.Tensor, y_test: torch.Tensor,\n","          optimizer, loss, epochs: int, batch_size: int):\n","    \n","    metric_names = ['loss', 'accuracy', 'f1_score']\n","    history = {phase_name: {metric_name: [] for metric_name in metric_names} for phase_name in ['train', 'test']}\n","\n","    for i in range(epochs):\n","        for j in tqdm(range(0, X_train.shape[0], batch_size)):\n","            # print(f\"epoch {i} batch {j}\")\n","            X_b_train = X_train[j:j+batch_size]\n","            y_b_train = y_train[j:j+batch_size]\n","            y_pred = model(X_b_train)\n","            loss_val = loss(y_pred, y_b_train)\n","            optimizer.zero_grad()\n","            loss_val.backward()\n","            optimizer.step()\n","\n","            y_pred_label = np.argmax(y_pred.detach().numpy(), axis=1)\n","            y_true_label = np.argmax(y_b_train.detach().numpy(), axis=1)\n","\n","            history['train']['accuracy'].append(np.mean(y_pred_label == y_true_label).item())\n","            history['train']['loss'].append(loss_val.item())\n","            history['train']['f1_score'].append(f1_score(y_true_label, y_pred_label, average='macro').item())\n","            \n","    return history"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["in_channels = 1\n","out_channels = 32\n","kernel_size = 3\n","stride = 1\n","padding = 1\n","bias = True\n","\n","height = X_train[0].shape[1]\n","width = X_train[0].shape[2]\n","\n","batch_size = 1024\n","epochs = 3\n","\n","model_torch = torch.nn.Sequential(\n","    torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n","    torch.nn.ReLU(),\n","    torch.nn.Flatten(), \n","    torch.nn.Linear(height * width * out_channels, 10),\n",")\n","\n","weights_data_torch = []\n","\n","optimizer_torch = torch.optim.Adam(model_torch.parameters(), lr=1e-3)\n","\n","loss_torch = torch.nn.CrossEntropyLoss()\n","\n","history_torch = train_torch(model_torch, X_train_torch, y_train_torch, X_test_torch, y_test_torch, optimizer_torch, loss_torch, epochs, batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for key, value in history_torch['train'].items():\n","    plt.plot(value)\n","    plt.title(key)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":4}
