# README не обновлено и не отражает текущую ситуацию
# Реализация ResNet-101, Adam, AbaBound (pytorch vs numpy)

<!-- 
## Задание:
1. Скачайте датасет [CarDatasets](https://drive.google.com/drive/folders/1pkudEBabqbXMxRTgfGQs3e0VqfTjtqWU)
2. Реализуйте ResNet-101 с оптимизатором [Adabound](https://arxiv.org/abs/1902.09843v1) с использованием
Numpy и с **Torch**/Tensorflow/Jax
3. Оцените качество модели на тесте и сравните быстродействие
реализованных вариантов.
4. Запустить обучение на классическом Adam и сравнить сходимость
результатов с вариантом задания.
5. Сделайте отчёт в виде readme на GitHub, там же должен быть выложен
исходный код.
-->

## Теоретическая база
### ResNet-101
![Здесь должно быть изображение с архитектурой ResNet-101. Оно должжно быть в папке images_for_readme](./images_for_readme/ResNet-101_Architecture_half_size.png)

![AdaBound algorythm](./images_for_readme/AdaBound.png)

![Adam](./images_for_readme/Adam.png)

<!--
ResNet-101 включает в себя свертку conv1, макс пулинг и далее множество коллекций слоев convi. convi_x является bottleneck'ом. Bottlencek состоит из трех сверток: 1x1, 3x3, 1x1. Первая свертка понижает число выходных каналов, последняя повышает.
Помимо сверток Bottleneck имеет identity mapping (точная копия входа Bottleneck'а), который складывается с выходом последней свертки Bottleneck'а. В случае, когда число каналов identity mapping'a не совападает с числом каналов выхода последней свертки, перед складыванием с conv3 над identity mapping'ом производится свертка 1x1, приводящая его к необходимой размерности.

В conv1 размерность плоскости входного тензора уменьшается вдвое в связи с тем, что stride = 2. Перед conv2_1 производится даунсемплинг карты признаков (feature map) в 2 раза с помощью max pooling'а. Далее conv3_1, conv_4_1 и conv5_1 первая свертка bottleneck'а имеет stride = 2. Таким образом, ширина и высота сходного "изображения" сужаются в 32 раза перед тем как дойти до average pooling, который оставляет одно значение для каждого канала. Такой пулинг позволяет использовать входные данные произвольной размерности. Тем не менее, в связи с понижением размерности при проходе через сеть вход должен быть не менее 32 и, желательно, кратен 32 (иначе тензоры будут "обрезаться").
-->

## Реализация и обучение resnet-101 на numpy
### Описание разработанной системы (алгоритмы, принципы работы, архитектура)
Весь код, связанный с реализацией и обучением resnet-101 на numpy, в директории [./numpy_CNN](./numpy_CNN).

В файле [./numpy_CNN/numpy_resnet.py](./numpy_CNN/numpy_resnet.py) реализация resnet-101 на numpy. Точнее, там находятся:
* реалиация `Bottleneck` residual block'а
* класс `ResNet`, который собирает архитектуру получая на вход список количеств residual ботлнеков каждой конфигурации 
* Функция `resnet101` вызывающая конструктор класса `ResNet` с количествами ботлнеков: [3, 4, 23, 3]

**Градиенты torch и numpy Bottleneck'ов перестали совпадать после того, как в обе реализации была добавлена батч нормализация.** Выходы совпадают даже у resnet целиком. *Возможно, проблема в том, что в torch батч-нормализации используется momentum. Мне казалось, что momentum = 1 приведет к ситуации, где не происходит скользящего усреднения, и обе версии будут иметь одинаковые градиенты. Интересно, что батч-нормализация проходит тест.*

Базовые модули сврточной нейронной сети, оптимизаторы и функция потерь реализованы в файле [./numpy_CNN/NumpyNN/NN_np](./numpy_CNN/NumpyNN/NN_np.py).

В моей реализации оптимизаторы получают на вход список слоёв. Каждый модуль нейронной сети (дочерние классы класса Layer, а также классы реализующие части нейронной сети или нейронную сеть целиком) имеют метод get_trainable_layers, возвращающий все обучаемые слои, входящие в состав модуля.

Реализованы классы:
* FullyConnectedLayer
* Conv2d — реализация свертки с помощью матричного умножения. Подробнее в [./numpy_CNN/NumpyNN/README.md](./numpy_CNN/NumpyNN/README.md).
* Conv2dWithLoops — имплементация свертки на циклах.
* MaxPool2d
* Flatten
* ReLULayer
* SigmoidLayer
* CrossEntropyLossWithSoftMax
* AdamOptimizer
* GradientDescentOptimizer
* Sequential
* BatchNormalization2d

В [./numpy_CNN/module_tests.ipynb](./numpy_CNN/module_tests.ipynb) производится проверка классов, реализованных на numpy путём сравнения результатов с аналогичными классами на pytorch. Для этого две реализации инициализируются одинаковыми весами (если речь об обучаемом модуле нейронной сети), в качетве входны данных и градиента по выходу генерируются тезоры случайных чисел. Сравниваются выходы, а также градиенты по весам, смещениям (bias) и входным данным. **В частности, было проверено, что resnet101, реализованный на numpy и на torch при одинаковых весах, входных данных и градиентах по выходным данным возвращают одинаковые выходные данные и одинаковые градиенты по входным данным**.

В [./numpy_CNN/numpy_CNN.ipynb](./numpy_CNN/numpy_CNN.ipynb) произведено обучение на датасете MNIST нейронной сети, состоящей из одого сверточного слоя, активации ReLU и одного полносвязного слоя. Активация последнего слоя - софтмакс, функция потерь - кросс-энтропия, оптимизатор - Адам. Результаты обучения на 3-ех эпохах представлены на графиках ниже. 

train:

![train loss](./images_for_readme/np_CNN_train_loss.png)
![train accuracy](./images_for_readme/np_CNN_train_accuracy.png)
![train f_score](./images_for_readme/np_CNN_train_fscore.png)

test:

![test loss](./images_for_readme/np_CNN_test_loss.png)
![test accuracy](./images_for_readme/np_CNN_test_accuracy.png)
![test f_score](./images_for_readme/np_CNN_test_fscore.png)


Ниже результаты обучения реализации numpy версии resnet101 с Adam на 1/10 датасета MNIST в течении 1 эпохи. На графиках батчевые метрики.
![numpy resnet101 batch metrics](./images_for_readme/numpy_resnet101_batch_metrics.png)

![numpy resnet101 epoch metrics](./images_for_readme/numpy_resnet101_epoch_metrics.png)


## Реализация resnet-101 на torch и сравнение обучения с использованием Adam и AdaBound
### Описание разработанной системы (алгоритмы, принципы работы, архитектура)
Весь код находится в директории [./pytorch_implementations](./pytorch_implementations).

В [.\pytorch_implementations\resnet.py](.\pytorch_implementations\resnet.py) Находится моя имплементация resnet на pytorch. Классы аналогичны описанным выше для numpy.

В моей имплементации нет батч-нормализации.

В [.\pytorch_implementations\resnet-adam-vs-adabound.ipynb](.\pytorch_implementations\resnet-adam-vs-adabound.ipynb) сравнивается обучение на датасете [Stanford Cars](http://ai.stanford.edu/~jkrause/cars/car_dataset.html) моей и оффициальной имплементаций resnet101 с оптимизаторами Adam и AdaBound.

Чтобы сравнение было честным и воспроизводимым перед обучением моей имплементации модели инициализировались одинаковыми весами. К сожалению, аналогичного действия по отношению к официальной имплементации не было произведено.

Из исходных изображений оставляется только участок, содержащий машину. Затем производится преобразование к одноканальному изображению в оттенках серого и сжатие до 96x96. 

### Результаты работы и тестирования системы (скриншоты, изображения, графики, закономерности)

*Все графики обучкения более гладцие, так как валидация производилась в 4 раза реже обучения*

Ниже результаты обучения моей имплементации resnet101 на torch c Adam (синий) и с AdaBound (оранжевый) learning rate = 0.002.

![my torch results](./images_for_readme/results_my_torch_resnet.png)

Ниже отдельно результаты обучения моей имплементации resnet101 на torch c  AdaBound.

![my torch results AdaBound](./images_for_readme/results_my_torch_resnet_AdaBound.png)

Ниже результаты обучения оффициальной имплементации resnet101 на torch c Adam (синий) и с AdaBound (оранжевый) learning rate = 0.001.

![official torch results](./images_for_readme/results_official_torch_resnet.png)

### Выводы по работе

Очевидно, работать с моделями, используя фреймворки удобнее, так как они высокооптимизированы и поддерживают cuda.

Исползование реализации свертки в виде матричного умножения делает прямое и обратное распространение сопоставимыми по времени с torch (продемонстрировано в конце [./numpy_CNN/module_tests.ipynb](./numpy_CNN/module_tests.ipynb)). Например, при параметрах n_input_channels = 4,n_output_channels = 2, width = 3, height = 5, kernel_size = 3, stride = 1, padding = 3 и batchsize = 8 1000 итераций обратного распространения на pytorch занимают 1.2 секунды, при матричной имлементации свертки - 1.8 секунды, а на циклах - 20.3 секунды.

Так как основное различие моей имплементации resnet101 на pytorch и официальной имплементации - отсутствие батч-нормализации, можно сделать вывод о важности батч-нормализации для скорости обучения.

При обучении моей имплементации c Adabound функция потерь падает невероятно медленно и по сравненю с Adam выглядит как прямая линия.

Обучение официально имлементации resnet101 тоже было медленне с AdaBound.

В данном эксперименте не было выявлено заявленных преимуществ AdaBound.

<!--
## To do:

* Добавить нормализацию изображений Stanford Cars датасета
* Так как машины не квадратные, возможно, лучше приводить к размеру 64x96
* Переписать [./numpy_CNN/NumpyNN/NN_np](./numpy_CNN/NumpyNN/NN_np.py), чтобы оптимизаторы принимали параметры, а не обучаемые слои. (Уже ведется работа в отдельном branch'е)
* Сделать методы сохранения параметров модели (или обучаемых слоев модели) в файл и загрузки из файла. Как минимум потому что обучаемые слои хранят входные данные => Если делать pickle модели целиком, записывется много бесполезной информации 
* Сделать вариант forward и backward Conv2d, где forward не сохраняет преобразованные input, а backward применяет преобразование к исходному input. Будет работать немного медленнее, но сильно сэкономит память
* Добавить Average pooling и reshape в resnet на numpy. Сейчас их нет и resnet на numpy умеет работать только с изображениями 32x32.
-->
## Использованные источники
1. [Adabound](https://arxiv.org/abs/1902.09843v1)
2. [Adam](https://arxiv.org/abs/1412.6980)
3. [ResNet](https://arxiv.org/pdf/1512.03385.pdf)

