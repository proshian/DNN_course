{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59a56421",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SystemPoint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from NumpyNN.NN_np import (\n",
    "    FullyConnectedLayer,\n",
    "    ReLULayer,\n",
    "    SigmoidLayer,\n",
    "    ReLULayer,\n",
    "    AdamOptimizer,\n",
    "    CrossEntropyLoss,\n",
    "    LinearActivation,\n",
    "    Sequential,\n",
    "    Optimizer,\n",
    "    SoftMaxLayer,\n",
    "    GradientDescentOptimizer,\n",
    "    CrossEntropyLossWithSoftMax,\n",
    "    Conv2d,\n",
    "    Conv2dWithLoops,\n",
    "    Flatten,\n",
    "    MaxPool2d,\n",
    "    AdamOptimizer,\n",
    "    BatchNormalization2d,\n",
    ")\n",
    "\n",
    "from numpy_resnet import Bottleneck, resnet101\n",
    "\n",
    "plt.gray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a12d3d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "sys.path.append(\n",
    "    sys.path[0].removesuffix(\"numpy_CNN\") + \"pytorch_implementations\"\n",
    ")\n",
    "\n",
    "from resnet import Bottleneck as Bottleneck_torch\n",
    "from resnet import resnet101 as resnet101_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7e86a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output all close: True\n",
      "w gradients all close: True\n",
      "b gradients all close: True\n",
      "input gradients all close: True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "FullyConnectedLayer test\n",
    "\"\"\"\n",
    "\n",
    "n_input_features = 6\n",
    "n_output_features = 3\n",
    "n_samples = 5\n",
    "input_data = np.random.rand(n_samples, n_input_features).astype(np.float32)\n",
    "input_data_torch = torch.from_numpy(input_data).float()\n",
    "input_data_torch.requires_grad = True\n",
    "output_gradient = np.random.rand(n_samples, n_output_features).astype(np.float32)\n",
    "\n",
    "torch_fc = torch.nn.Linear(n_input_features, n_output_features)\n",
    "torch_out = torch_fc(input_data_torch)\n",
    "torch_out_np = torch_out.detach().numpy()\n",
    "torch_out.backward(torch.tensor(output_gradient), retain_graph=True)\n",
    "torch_wg = torch_fc.weight.grad.detach().numpy().T\n",
    "torch_bg = torch_fc.bias.grad.detach().numpy().reshape(-1, 1).T\n",
    "# torch_input_g = input_data_torch.grad.detach().numpy()\n",
    "\n",
    "\n",
    "my_fc = FullyConnectedLayer(n_input_features, n_output_features)\n",
    "my_fc.weights = torch_fc.weight.detach().numpy().T\n",
    "my_fc.bias = torch_fc.bias.detach().numpy().reshape(-1, 1).T\n",
    "my_out = my_fc.forward(input_data)\n",
    "my_input_g = my_fc.backward(output_gradient)\n",
    "my_wg = my_fc.weights_gradient\n",
    "my_bg = my_fc.bias_gradient\n",
    "\n",
    "\n",
    "print(\"output all close:\", np.allclose(my_out, torch_out_np))\n",
    "print(\"w gradients all close:\", np.allclose(my_wg, torch_wg))\n",
    "print(\"b gradients all close:\", np.allclose(my_bg, torch_bg))\n",
    "print(\"input gradients all close:\", np.allclose(my_input_g, input_data_torch.grad))\n",
    "# print(\"input gradients all close:\", np.allclose(my_input_g, torch_bg))\n",
    "\n",
    "# print(\"all parameters shape same: \", my_fc.weights.shape == torch_fc.weight.T.shape and my_fc.bias.shape == torch.unsqueeze(torch_fc.bias, 1).shape)\n",
    "# print(\"output sum of square dif:\", np.square(my_out - torch_out_np).sum())\n",
    "# print(torch_wg.sum(), my_wg.sum())\n",
    "# print(\"w gradient sum of square dif:\", np.square(my_wg - torch_wg).sum())\n",
    "\n",
    "#print()\n",
    "#print(my_wg)\n",
    "#print()\n",
    "#print(torch_wg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba7f546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_val all close: True\n",
      "loss gradients all close: True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CrossEntropyLoss test\n",
    "\"\"\"\n",
    "def one_hot(y: np.ndarray, n_classes: int):\n",
    "    encoded = np.zeros((y.size, n_classes))\n",
    "    encoded[np.arange(y.size), y] = 1\n",
    "    return encoded\n",
    "\n",
    "\n",
    "batch_size = 5\n",
    "n_classes = 3\n",
    "pred = np.random.rand(batch_size, n_classes).astype(np.float32)\n",
    "true = one_hot(np.random.randint(0, n_classes, batch_size), n_classes)\n",
    "pred_torch = torch.from_numpy(pred).float()\n",
    "true_torch = torch.from_numpy(true).float()\n",
    "pred_torch.requires_grad = True\n",
    "\n",
    "torch_loss  = torch.nn.CrossEntropyLoss()\n",
    "torch_loss_val = torch_loss(pred_torch, true_torch)\n",
    "torch_loss_val.backward()\n",
    "\n",
    "my_loss = CrossEntropyLossWithSoftMax()\n",
    "my_loss_val = my_loss.forward(pred, true)\n",
    "my_loss.backward()\n",
    "\n",
    "print(\"loss_val all close:\", np.allclose(my_loss_val, torch_loss_val.detach().numpy()))\n",
    "print(\"loss gradients all close:\", np.allclose(my_loss.backward(), pred_torch.grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99dabc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output all close: True\n",
      "input gradients all close: True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ReLULayer test\n",
    "\"\"\"\n",
    "\n",
    "n_input_features = 6\n",
    "n_output_features = 3\n",
    "n_samples = 5\n",
    "input_data = np.random.rand(n_samples, n_input_features).astype(np.float32)\n",
    "input_data_torch = torch.from_numpy(input_data).float()\n",
    "input_data_torch.requires_grad = True\n",
    "output_gradient = np.random.rand(n_samples, n_input_features).astype(np.float32)\n",
    "\n",
    "\n",
    "torch_relu = torch.nn.ReLU()\n",
    "torch_out = torch_relu(input_data_torch)\n",
    "torch_out_np = torch_out.detach().numpy()\n",
    "torch_out.backward(torch.tensor(output_gradient), retain_graph=True)\n",
    "# torch_input_g = input_data_torch.grad.detach().numpy()\n",
    "\n",
    "\n",
    "my_relu = ReLULayer()\n",
    "my_out = my_relu.forward(input_data)\n",
    "\n",
    "\n",
    "print(\"output all close:\", np.allclose(my_out, torch_out_np))\n",
    "print(\"input gradients all close:\", np.allclose(my_relu.backward(output_gradient), input_data_torch.grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "461e801f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output all close: True\n",
      "input gradients all close: True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SigmoidLayer test\n",
    "\"\"\"\n",
    "\n",
    "n_input_features = 6\n",
    "n_output_features = 3\n",
    "n_samples = 5\n",
    "input_data = np.random.rand(n_samples, n_input_features).astype(np.float32)\n",
    "input_data_torch = torch.from_numpy(input_data).float()\n",
    "input_data_torch.requires_grad = True\n",
    "output_gradient = np.random.rand(n_samples, n_input_features).astype(np.float32)\n",
    "\n",
    "\n",
    "torch_sigmoid = torch.nn.Sigmoid()\n",
    "torch_out = torch_sigmoid(input_data_torch)\n",
    "torch_out_np = torch_out.detach().numpy()\n",
    "torch_out.backward(torch.tensor(output_gradient), retain_graph=True)\n",
    "# torch_input_g = input_data_torch.grad.detach().numpy()\n",
    "\n",
    "\n",
    "my_sigmoid = SigmoidLayer()\n",
    "my_out = my_sigmoid.forward(input_data)\n",
    "\n",
    "\n",
    "print(\"output all close:\", np.allclose(my_out, torch_out_np))\n",
    "print(\"input gradients all close:\", np.allclose(my_sigmoid.backward(output_gradient), input_data_torch.grad))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df1d5da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output all close: True\n",
      "input gradients all close: True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SigmoidLayer test on a 4D tensor\n",
    "\"\"\"\n",
    "\n",
    "n_input_channels = 3\n",
    "n_samples = 2\n",
    "height = 5\n",
    "width = 5\n",
    "input_data = np.random.rand(n_samples, n_input_channels, height, width).astype(np.float32)\n",
    "input_data_torch = torch.from_numpy(input_data).float()\n",
    "input_data_torch.requires_grad = True\n",
    "output_gradient = np.random.rand(n_samples, n_input_channels, height, width).astype(np.float32)\n",
    "\n",
    "\n",
    "torch_sigmoid = torch.nn.Sigmoid()\n",
    "torch_out = torch_sigmoid(input_data_torch)\n",
    "torch_out_np = torch_out.detach().numpy()\n",
    "torch_out.backward(torch.tensor(output_gradient), retain_graph=True)\n",
    "# torch_input_g = input_data_torch.grad.detach().numpy()\n",
    "\n",
    "\n",
    "my_sigmoid = SigmoidLayer()\n",
    "my_out = my_sigmoid.forward(input_data)\n",
    "\n",
    "\n",
    "print(\"output all close:\", np.allclose(my_out, torch_out_np))\n",
    "print(\"input gradients all close:\", np.allclose(my_sigmoid.backward(output_gradient), input_data_torch.grad))\n",
    "# print(\"input gradients all close:\", np.allclose(my_input_g, torch_bg))\n",
    "\n",
    "# print(\"all parameters shape same: \", my_fc.weights.shape == torch_fc.weight.T.shape and my_fc.bias.shape == torch.unsqueeze(torch_fc.bias, 1).shape)\n",
    "# print(\"output sum of square dif:\", np.square(my_out - torch_out_np).sum())\n",
    "# print(torch_wg.sum(), my_wg.sum())\n",
    "# print(\"w gradient sum of square dif:\", np.square(my_wg - torch_wg).sum())\n",
    "\n",
    "#print()\n",
    "#print(my_wg)\n",
    "#print()\n",
    "#print(torch_wg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65f81748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output all close: True\n",
      "input gradients all close: True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "FlattenLayer test\n",
    "\"\"\"\n",
    "\n",
    "n_input_channels = 3\n",
    "n_samples = 2\n",
    "height = 5\n",
    "width = 5\n",
    "\n",
    "input_data = np.random.rand(n_samples, n_input_channels, height, width).astype(np.float32)\n",
    "input_data_torch = torch.from_numpy(input_data).float()\n",
    "input_data_torch.requires_grad = True\n",
    "output_gradient = np.random.rand(n_samples, n_input_channels * height * width).astype(np.float32)\n",
    "\n",
    "my_flatten = Flatten()\n",
    "my_out = my_flatten.forward(input_data)\n",
    "my_out_g = my_flatten.backward(output_gradient)\n",
    "\n",
    "torch_flatten = torch.nn.Flatten()\n",
    "torch_out = torch_flatten(input_data_torch)\n",
    "torch_out_np = torch_out.detach().numpy()\n",
    "\n",
    "torch_out.backward(torch.tensor(output_gradient), retain_graph=True)\n",
    "torch_input_g = input_data_torch.grad.detach().numpy()\n",
    "\n",
    "print(\"output all close:\", np.allclose(my_out, torch_out_np))\n",
    "print(\"input gradients all close:\", np.allclose(my_out_g, torch_input_g))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ea63232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output all close: True\n",
      "weights gradients all close: True\n",
      "bias gradients all close: True\n",
      "input gradients all close: True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Conv2dWithLoops test\n",
    "\"\"\"\n",
    "\n",
    "batch_size = 5\n",
    "n_input_channels = 4\n",
    "n_output_channels = 2\n",
    "width = 3\n",
    "height = 5\n",
    "\n",
    "kernel_size = 3\n",
    "stride = 1\n",
    "padding = 1\n",
    "\n",
    "output_width = (width + 2 * padding - kernel_size) // stride + 1\n",
    "output_height = (height + 2 * padding - kernel_size) // stride + 1\n",
    "\n",
    "input_data = np.random.rand(batch_size, n_input_channels, width, height).astype(np.float32)\n",
    "input_data_torch = torch.from_numpy(input_data).float()\n",
    "input_data_torch.requires_grad = True\n",
    "output_gradient = np.random.rand(batch_size, n_output_channels, output_width, output_height).astype(np.float32)\n",
    "\n",
    "torch_conv = torch.nn.Conv2d(n_input_channels, n_output_channels, kernel_size, stride, padding)\n",
    "\n",
    "my_conv = Conv2dWithLoops(n_input_channels, n_output_channels, kernel_size, stride, padding)\n",
    "my_conv.weights = torch_conv.weight.detach().numpy()\n",
    "my_conv.bias = torch_conv.bias.detach().numpy().reshape(-1, 1)\n",
    "\n",
    "my_out = my_conv.forward(input_data)\n",
    "\n",
    "torch_out = torch_conv(input_data_torch)\n",
    "torch_out_np = torch_out.detach().numpy()\n",
    "torch_out.backward(torch.tensor(output_gradient), retain_graph=True)\n",
    "torch_input_g = input_data_torch.grad.detach().numpy()\n",
    "torch_wg = torch_conv.weight.grad.detach().numpy()\n",
    "torch_bg = torch_conv.bias.grad.detach().numpy().reshape(-1, 1)\n",
    "\n",
    "# print(torch_conv.weight.shape, torch_conv.bias.shape)\n",
    "# print(my_conv.weights.shape, my_conv.bias.shape)\n",
    "my_input_g = my_conv.backward(output_gradient)\n",
    "\n",
    "atol=1e-6\n",
    "\n",
    "print(\"output all close:\", np.allclose(my_out, torch_out_np, atol=atol))\n",
    "\n",
    "print(\"weights gradients all close:\", np.allclose(my_conv.weights_gradient, torch_wg, atol=atol ))\n",
    "\n",
    "print(\"bias gradients all close:\", np.allclose(my_conv.bias_gradient, torch_bg, atol=atol))\n",
    "\n",
    "print(\"input gradients all close:\", np.allclose(my_input_g, torch_input_g, atol=atol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bba16408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output all close: True\n",
      "weights gradients all close: True\n",
      "bias gradients all close: True\n",
      "input gradients all close: True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Conv2d test\n",
    "\"\"\"\n",
    "\n",
    "batch_size = 2\n",
    "n_input_channels = 2\n",
    "n_output_channels = 2\n",
    "width = 4\n",
    "height = 4\n",
    "\n",
    "kernel_size = 2\n",
    "stride = 1\n",
    "padding = 0\n",
    "\n",
    "output_width = (width + 2 * padding - kernel_size) // stride + 1\n",
    "output_height = (height + 2 * padding - kernel_size) // stride + 1\n",
    "\n",
    "input_data = np.random.rand(batch_size, n_input_channels, height, width).astype(np.float32)\n",
    "input_data_torch = torch.from_numpy(input_data).float()\n",
    "input_data_torch.requires_grad = True\n",
    "output_gradient = np.random.rand(batch_size, n_output_channels, output_height, output_width).astype(np.float32)\n",
    "\n",
    "torch_conv = torch.nn.Conv2d(n_input_channels, n_output_channels, kernel_size, stride, padding)\n",
    "\n",
    "my_conv = Conv2d(n_input_channels, n_output_channels, kernel_size, stride, padding)\n",
    "my_conv.weights = torch_conv.weight.detach().numpy()\n",
    "if my_conv.bias is not None:\n",
    "    my_conv.bias = torch_conv.bias.detach().numpy().reshape(-1, 1)\n",
    "\n",
    "my_out = my_conv.forward(input_data)\n",
    "\n",
    "torch_out = torch_conv(input_data_torch)\n",
    "torch_out_np = torch_out.detach().numpy()\n",
    "torch_out.backward(torch.tensor(output_gradient), retain_graph=True)\n",
    "torch_input_g = input_data_torch.grad.detach().numpy()\n",
    "torch_wg = torch_conv.weight.grad.detach().numpy()\n",
    "if my_conv.bias is not None:\n",
    "    torch_bg = torch_conv.bias.grad.detach().numpy().reshape(-1, 1)\n",
    "\n",
    "# print(torch_conv.weight.shape, torch_conv.bias.shape)\n",
    "# print(my_conv.weights.shape, my_conv.bias.shape)\n",
    "my_input_g = my_conv.backward(output_gradient)\n",
    "\n",
    "\n",
    "atol=1e-6\n",
    "\n",
    "print(\"output all close:\", np.allclose(my_out, torch_out_np, atol=atol))\n",
    "\n",
    "print(\"weights gradients all close:\", np.allclose(my_conv.weights_gradient, torch_wg, atol=atol ))\n",
    "if my_conv.bias is not None:\n",
    "    print(\"bias gradients all close:\", np.allclose(my_conv.bias_gradient, torch_bg, atol=atol))\n",
    "\n",
    "print(\"input gradients all close:\", np.allclose(my_input_g, torch_input_g, atol=atol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ccdb4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output all close: True\n",
      "weights gradients all close: True\n",
      "input gradients all close: True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Conv2d test 2\n",
    "\"\"\"\n",
    "\n",
    "batch_size = 3\n",
    "n_input_channels = 1\n",
    "n_output_channels = 64\n",
    "width = 32\n",
    "height = 32\n",
    "\n",
    "kernel_size = 7\n",
    "stride = 2\n",
    "padding = 3\n",
    "\n",
    "output_width = (width + 2 * padding - kernel_size) // stride + 1\n",
    "output_height = (height + 2 * padding - kernel_size) // stride + 1\n",
    "\n",
    "input_data = np.random.rand(batch_size, n_input_channels, height, width).astype(np.float32)\n",
    "input_data_torch = torch.from_numpy(input_data).float()\n",
    "input_data_torch.requires_grad = True\n",
    "output_gradient = np.random.rand(batch_size, n_output_channels, output_height, output_width).astype(np.float32)\n",
    "\n",
    "torch_conv = torch.nn.Conv2d(n_input_channels, n_output_channels, kernel_size, stride, padding, bias=False)\n",
    "\n",
    "my_conv = Conv2d(n_input_channels, n_output_channels, kernel_size, stride, padding, bias=False)\n",
    "my_conv.weights = torch_conv.weight.detach().numpy()\n",
    "if my_conv.bias is not None:\n",
    "    my_conv.bias = torch_conv.bias.detach().numpy().reshape(my_conv.bias.shape)\n",
    "\n",
    "my_out = my_conv.forward(input_data)\n",
    "\n",
    "torch_out = torch_conv(input_data_torch)\n",
    "torch_out_np = torch_out.detach().numpy()\n",
    "torch_out.backward(torch.tensor(output_gradient), retain_graph=True)\n",
    "torch_input_g = input_data_torch.grad.detach().numpy()\n",
    "torch_wg = torch_conv.weight.grad.detach().numpy()\n",
    "if my_conv.bias is not None:\n",
    "    torch_bg = torch_conv.bias.grad.detach().numpy().reshape(my_conv.bias.shape)\n",
    "\n",
    "# print(torch_conv.weight.shape, torch_conv.bias.shape)\n",
    "# print(my_conv.weights.shape, my_conv.bias.shape)\n",
    "my_input_g = my_conv.backward(output_gradient)\n",
    "\n",
    "\n",
    "atol=1e-6\n",
    "\n",
    "print(\"output all close:\", np.allclose(my_out, torch_out_np, atol=atol))\n",
    "\n",
    "print(\"weights gradients all close:\", np.allclose(my_conv.weights_gradient, torch_wg, atol=atol ))\n",
    "if my_conv.bias is not None:\n",
    "    print(\"bias gradients all close:\", np.allclose(my_conv.bias_gradient, torch_bg, atol=atol))\n",
    "\n",
    "print(\"input gradients all close:\", np.allclose(my_input_g, torch_input_g, atol=atol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "910f5e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "n_input_channels = 4\n",
    "n_output_channels = 5\n",
    "width = 32\n",
    "height = 32\n",
    "\n",
    "kernel_size = 5\n",
    "stride = 1\n",
    "padding = 1\n",
    "\n",
    "my_conv = Conv2d(n_input_channels, n_output_channels, kernel_size, stride, padding, bias=False)\n",
    "\n",
    "big_input = np.random.rand(2, 5, 10, 10).astype(np.float32)   \n",
    "\n",
    "converted_input = my_conv._convert_input(big_input)\n",
    "\n",
    "restored_input = my_conv._restore_input(converted_input, big_input.shape)\n",
    "\n",
    "np.allclose(restored_input, big_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "970ee26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output all close: True\n",
      "input gradients all close: True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MaxPool2d test\n",
    "\"\"\"\n",
    "\n",
    "batch_size = 2\n",
    "n_channels = 3\n",
    "height = 6\n",
    "width = 4\n",
    "\n",
    "kernel_size = 2\n",
    "stride = 1\n",
    "padding = 0\n",
    "\n",
    "output_width = (width + 2 * padding - kernel_size) // stride + 1\n",
    "output_height = (height + 2 * padding - kernel_size) // stride + 1\n",
    "\n",
    "input_data = np.random.rand(batch_size, n_channels, height, width).astype(np.float32)\n",
    "input_data_torch = torch.from_numpy(input_data).float()\n",
    "input_data_torch.requires_grad = True\n",
    "output_gradient = np.random.rand(batch_size, n_channels, output_height, output_width).astype(np.float32)\n",
    "\n",
    "torch_pool = torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
    "\n",
    "my_pool = MaxPool2d(kernel_size, stride, padding)\n",
    "\n",
    "my_out = my_pool.forward(input_data)\n",
    "\n",
    "torch_out = torch_pool(input_data_torch)\n",
    "torch_out_np = torch_out.detach().numpy()\n",
    "torch_out.backward(torch.tensor(output_gradient), retain_graph=True)\n",
    "torch_input_g = input_data_torch.grad.detach().numpy()\n",
    "\n",
    "my_input_g = my_pool.backward(output_gradient)\n",
    "\n",
    "atol=1e-6\n",
    "\n",
    "print(\"output all close:\", np.allclose(my_out, torch_out_np, atol=atol))\n",
    "print(\"input gradients all close:\", np.allclose(my_input_g, torch_input_g, atol=atol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47856b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output all close: True\n",
      "input gradients all close: True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MaxPool2d test 2\n",
    "\"\"\"\n",
    "\n",
    "batch_size = 10\n",
    "n_channels = 3\n",
    "height = 16\n",
    "width = 16\n",
    "\n",
    "kernel_size = 3\n",
    "stride = 2\n",
    "padding = 1\n",
    "\n",
    "output_width = (width + 2 * padding - kernel_size) // stride + 1\n",
    "output_height = (height + 2 * padding - kernel_size) // stride + 1\n",
    "\n",
    "input_data = np.random.rand(batch_size, n_channels, height, width).astype(np.float32)\n",
    "input_data_torch = torch.from_numpy(input_data).float()\n",
    "input_data_torch.requires_grad = True\n",
    "output_gradient = np.random.rand(batch_size, n_channels, output_height, output_width).astype(np.float32)\n",
    "\n",
    "torch_pool = torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
    "\n",
    "my_pool = MaxPool2d(kernel_size, stride, padding)\n",
    "\n",
    "my_out = my_pool.forward(input_data)\n",
    "\n",
    "torch_out = torch_pool(input_data_torch)\n",
    "torch_out_np = torch_out.detach().numpy()\n",
    "torch_out.backward(torch.tensor(output_gradient), retain_graph=True)\n",
    "torch_input_g = input_data_torch.grad.detach().numpy()\n",
    "\n",
    "my_input_g = my_pool.backward(output_gradient)\n",
    "\n",
    "atol=1e-6\n",
    "\n",
    "print(\"output all close:\", np.allclose(my_out, torch_out_np, atol=atol))\n",
    "print(\"input gradients all close:\", np.allclose(my_input_g, torch_input_g, atol=atol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b5717f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stride = 1\n",
      "output all close: False\n",
      "input gradients all close: False\n",
      "conv1 weights gradients all close: False\n",
      "conv2 weights gradients all close: False\n",
      "conv3 weights gradients all close: False\n",
      "bn3 gamma gradients all close: False\n",
      "bn3 beta gradients all close: False\n",
      "\n",
      "stride = 2\n",
      "output all close: False\n",
      "input gradients all close: False\n",
      "conv1 weights gradients all close: False\n",
      "conv2 weights gradients all close: False\n",
      "conv3 weights gradients all close: False\n",
      "conv_to_match_dimensions weights gradients all close: False\n",
      "bn3 gamma gradients all close: False\n",
      "bn3 beta gradients all close: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "BottleNeckLayer test\n",
    "\"\"\"\n",
    "\n",
    "batch_size = 5\n",
    "in_channels = 8\n",
    "bottleneck_depth = 2\n",
    "width = 6\n",
    "height = 6\n",
    "\n",
    "expansion_factor = 4\n",
    "n_output_channels = bottleneck_depth * expansion_factor\n",
    "\n",
    "for stride_for_downsampling in (1, 2):  # Checking both cases: no downsampling and downsampling\n",
    "    print(f\"stride = {stride_for_downsampling}\")\n",
    "    input_data = np.random.rand(batch_size, in_channels, width, height).astype(np.float32)\n",
    "    input_data_torch = torch.from_numpy(input_data).float()\n",
    "    input_data_torch.requires_grad = True\n",
    "\n",
    "    if stride_for_downsampling == 1:\n",
    "        output_width = width\n",
    "        output_height = height\n",
    "    if stride_for_downsampling == 2:\n",
    "        output_width = width // stride_for_downsampling\n",
    "        output_height = height // stride_for_downsampling\n",
    "    output_gradient = np.random.rand(batch_size, n_output_channels, output_width, output_height).astype(np.float32)\n",
    "\n",
    "    torch_bottleneck = Bottleneck_torch(in_channels, bottleneck_depth, stride_for_downsampling)\n",
    "    my_bottleneck = Bottleneck(in_channels, bottleneck_depth, stride_for_downsampling)\n",
    "\n",
    "    my_bottleneck.conv1.weights = torch_bottleneck.conv1.weight.detach().numpy().reshape(my_bottleneck.conv1.weights.shape)\n",
    "    my_bottleneck.conv2.weights = torch_bottleneck.conv2.weight.detach().numpy()\n",
    "    my_bottleneck.conv3.weights = torch_bottleneck.conv3.weight.detach().numpy()\n",
    "\n",
    "    my_bottleneck.bn1.gamma = torch_bottleneck.bn1.weight.detach().numpy().reshape(my_bottleneck.bn1.gamma.shape)\n",
    "    my_bottleneck.bn1.beta = torch_bottleneck.bn1.bias.detach().numpy().reshape(my_bottleneck.bn1.beta.shape)\n",
    "    my_bottleneck.bn1.mean = torch_bottleneck.bn1.running_mean.detach().numpy().reshape(my_bottleneck.bn1.mean.shape)\n",
    "    my_bottleneck.bn1.var = torch_bottleneck.bn1.running_var.detach().numpy().reshape(my_bottleneck.bn1.var.shape)\n",
    "    torch_bottleneck.bn1.momentum = 1.0\n",
    "\n",
    "    my_bottleneck.bn2.gamma = torch_bottleneck.bn2.weight.detach().numpy().reshape(my_bottleneck.bn2.gamma.shape)\n",
    "    my_bottleneck.bn2.beta = torch_bottleneck.bn2.bias.detach().numpy().reshape(my_bottleneck.bn2.beta.shape)\n",
    "    my_bottleneck.bn2.mean = torch_bottleneck.bn2.running_mean.detach().numpy().reshape(my_bottleneck.bn2.mean.shape)\n",
    "    my_bottleneck.bn2.var = torch_bottleneck.bn2.running_var.detach().numpy().reshape(my_bottleneck.bn2.var.shape)\n",
    "    torch_bottleneck.bn2.momentum = 1.0\n",
    "\n",
    "    my_bottleneck.bn3.gamma = torch_bottleneck.bn3.weight.detach().numpy().reshape(my_bottleneck.bn3.gamma.shape)\n",
    "    my_bottleneck.bn3.beta = torch_bottleneck.bn3.bias.detach().numpy().reshape(my_bottleneck.bn3.beta.shape)\n",
    "    my_bottleneck.bn3.mean = torch_bottleneck.bn3.running_mean.detach().numpy().reshape(my_bottleneck.bn3.mean.shape)\n",
    "    my_bottleneck.bn3.var = torch_bottleneck.bn3.running_var.detach().numpy().reshape(my_bottleneck.bn3.var.shape)\n",
    "    torch_bottleneck.bn3.momentum = 1.0\n",
    "\n",
    "\n",
    "    if my_bottleneck.conv_to_match_dimensions:\n",
    "        my_bottleneck.conv_to_match_dimensions.weights = torch_bottleneck.conv_to_match_dimensions.weight.detach().numpy()\n",
    "        my_bottleneck.bn_for_residual.gamma = torch_bottleneck.bn_for_residual.weight.detach().numpy().reshape(my_bottleneck.bn_for_residual.gamma.shape)\n",
    "        my_bottleneck.bn_for_residual.beta = torch_bottleneck.bn_for_residual.bias.detach().numpy().reshape(my_bottleneck.bn_for_residual.beta.shape)\n",
    "        my_bottleneck.bn_for_residual.mean = torch_bottleneck.bn_for_residual.running_mean.detach().numpy().reshape(my_bottleneck.bn_for_residual.mean.shape)\n",
    "        my_bottleneck.bn_for_residual.var = torch_bottleneck.bn_for_residual.running_var.detach().numpy().reshape(my_bottleneck.bn_for_residual.var.shape)\n",
    "        torch_bottleneck.bn_for_residual.momentum = 1.0\n",
    "    \n",
    "    my_bottleneck.eval()\n",
    "    torch_bottleneck.eval()\n",
    "\n",
    "    my_out = my_bottleneck.forward(input_data)\n",
    "    torch_out = torch_bottleneck(input_data_torch)\n",
    "\n",
    "    torch_out.backward(torch.tensor(output_gradient), retain_graph=True)\n",
    "    torch_input_g = input_data_torch.grad.detach().numpy()\n",
    "\n",
    "    my_input_g = my_bottleneck.backward(output_gradient)\n",
    "\n",
    "    atol = 1e-2\n",
    "    print(\"output all close:\", np.allclose(my_out, torch_out.detach().numpy(), atol=atol))\n",
    "    print(\"input gradients all close:\", np.allclose(my_input_g, torch_input_g, atol=atol))\n",
    "    print(\"conv1 weights gradients all close:\", np.allclose(my_bottleneck.conv1.weights_gradient, torch_bottleneck.conv1.weight.grad.detach().numpy(), atol=atol))\n",
    "    print(\"conv2 weights gradients all close:\", np.allclose(my_bottleneck.conv2.weights_gradient, torch_bottleneck.conv2.weight.grad.detach().numpy(), atol=atol))\n",
    "    print(\"conv3 weights gradients all close:\", np.allclose(my_bottleneck.conv3.weights_gradient, torch_bottleneck.conv3.weight.grad.detach().numpy(), atol=atol))\n",
    "    if my_bottleneck.conv_to_match_dimensions:\n",
    "        print(\"conv_to_match_dimensions weights gradients all close:\", np.allclose(my_bottleneck.conv_to_match_dimensions.weights_gradient, torch_bottleneck.conv_to_match_dimensions.weight.grad.detach().numpy(), atol=atol))\n",
    "    \n",
    "    print(\"bn3 gamma gradients all close:\", np.allclose(my_bottleneck.bn3.gamma_gradient, torch_bottleneck.bn3.weight.grad.detach().numpy(), atol=atol))  \n",
    "    print(\"bn3 beta gradients all close:\", np.allclose(my_bottleneck.bn3.beta_gradient, torch_bottleneck.bn3.bias.grad.detach().numpy(), atol=atol))  \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95acb0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000e+00, 7.2277e-01, 0.0000e+00],\n",
       "          [1.6486e-01, 0.0000e+00, 2.1370e+00],\n",
       "          [9.4435e-01, 1.4664e+00, 0.0000e+00]],\n",
       "\n",
       "         [[3.2072e-01, 0.0000e+00, 6.3461e-01],\n",
       "          [0.0000e+00, 2.0692e-01, 2.3397e-01],\n",
       "          [1.7653e+00, 0.0000e+00, 1.0693e-01]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 3.7922e-01],\n",
       "          [1.1902e-01, 0.0000e+00, 1.6515e+00],\n",
       "          [2.0296e+00, 2.2622e+00, 1.1896e+00]],\n",
       "\n",
       "         [[3.0679e-01, 0.0000e+00, 2.7092e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 4.2702e-01],\n",
       "          [4.2519e-01, 1.9376e+00, 0.0000e+00]],\n",
       "\n",
       "         [[6.4665e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [1.0320e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 2.2411e+00]],\n",
       "\n",
       "         [[0.0000e+00, 8.6591e-01, 0.0000e+00],\n",
       "          [2.5480e-01, 2.1553e-04, 2.8269e+00],\n",
       "          [9.4850e-01, 1.1253e+00, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 1.2735e+00],\n",
       "          [2.3342e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [6.7478e-01, 0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[5.0737e-01, 0.0000e+00, 6.2147e-02],\n",
       "          [6.8106e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 1.0968e+00]]],\n",
       "\n",
       "\n",
       "        [[[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 1.0399e+00],\n",
       "          [3.5731e+00, 1.8421e+00, 0.0000e+00]],\n",
       "\n",
       "         [[7.0538e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [1.1295e+00, 5.2564e-01, 0.0000e+00],\n",
       "          [9.7594e-01, 0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.5125e-01, 0.0000e+00, 1.3132e+00],\n",
       "          [1.8810e+00, 1.7230e+00, 0.0000e+00]],\n",
       "\n",
       "         [[4.0097e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [1.1144e+00, 0.0000e+00, 2.3295e-01],\n",
       "          [1.3902e+00, 6.9862e-02, 0.0000e+00]],\n",
       "\n",
       "         [[2.0582e+00, 9.9432e-01, 1.8509e+00],\n",
       "          [5.7792e-01, 1.9641e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 9.3324e-02, 2.8229e+00]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 7.9173e-01],\n",
       "          [3.5338e+00, 1.3207e+00, 0.0000e+00]],\n",
       "\n",
       "         [[1.1016e+00, 5.9936e-01, 8.4177e-01],\n",
       "          [1.0951e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [5.4882e-02, 0.0000e+00, 1.4268e+00]],\n",
       "\n",
       "         [[1.7725e+00, 1.1911e+00, 2.3444e+00],\n",
       "          [1.3694e+00, 1.4942e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 1.4430e+00]]],\n",
       "\n",
       "\n",
       "        [[[1.2260e+00, 7.2274e-02, 1.0240e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 2.6349e+00, 4.6966e-01]],\n",
       "\n",
       "         [[4.6158e-01, 0.0000e+00, 1.2964e+00],\n",
       "          [1.7050e-01, 5.2678e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 8.2947e-01, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.1289e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 7.9473e-01]],\n",
       "\n",
       "         [[4.4434e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [1.0229e+00, 0.0000e+00, 7.9198e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 2.1658e+00]],\n",
       "\n",
       "         [[1.1897e-01, 3.8324e-01, 0.0000e+00],\n",
       "          [1.2137e+00, 7.2762e-01, 2.0207e+00],\n",
       "          [1.0763e+00, 0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[1.3298e+00, 0.0000e+00, 1.6191e+00],\n",
       "          [0.0000e+00, 3.8337e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 3.3671e+00, 0.0000e+00]],\n",
       "\n",
       "         [[7.1925e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [9.6406e-01, 0.0000e+00, 1.9025e+00],\n",
       "          [7.9963e-01, 0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.1445e+00, 1.0957e+00, 1.5206e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[0.0000e+00, 1.9737e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 1.5034e-01],\n",
       "          [2.6026e+00, 0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[1.6105e-01, 0.0000e+00, 1.8902e-01],\n",
       "          [1.2294e+00, 5.5062e-01, 0.0000e+00],\n",
       "          [1.5752e+00, 7.2165e-01, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.4585e+00, 0.0000e+00, 1.9904e-01],\n",
       "          [3.4228e+00, 0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[1.4547e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [3.0669e+00, 0.0000e+00, 1.5303e+00],\n",
       "          [1.7026e+00, 8.1811e-02, 0.0000e+00]],\n",
       "\n",
       "         [[1.6807e+00, 1.0805e-01, 1.3828e+00],\n",
       "          [0.0000e+00, 6.7417e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 1.4285e+00]],\n",
       "\n",
       "         [[0.0000e+00, 6.1093e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 5.2124e-03],\n",
       "          [3.1524e+00, 3.2604e-02, 0.0000e+00]],\n",
       "\n",
       "         [[2.4182e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [2.7860e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [6.5576e-01, 0.0000e+00, 1.8636e+00]],\n",
       "\n",
       "         [[2.1126e+00, 0.0000e+00, 7.1359e-01],\n",
       "          [3.7680e-02, 6.9953e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 8.2885e-01, 2.3239e+00]]],\n",
       "\n",
       "\n",
       "        [[[1.1942e+00, 0.0000e+00, 2.6360e+00],\n",
       "          [0.0000e+00, 3.5675e+00, 0.0000e+00],\n",
       "          [7.5895e-01, 7.6545e-02, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 1.4403e+00, 2.5308e+00],\n",
       "          [1.8378e+00, 0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 5.9517e-01, 0.0000e+00],\n",
       "          [6.4626e-01, 1.6527e+00, 0.0000e+00],\n",
       "          [1.1170e+00, 3.5844e-01, 8.8645e-01]],\n",
       "\n",
       "         [[0.0000e+00, 1.9752e+00, 0.0000e+00],\n",
       "          [3.9550e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [2.1482e+00, 1.4855e+00, 9.9219e-02]],\n",
       "\n",
       "         [[5.6177e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [1.4725e+00, 0.0000e+00, 8.4891e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 8.6983e-02]],\n",
       "\n",
       "         [[9.0202e-01, 0.0000e+00, 2.0891e+00],\n",
       "          [0.0000e+00, 3.4859e+00, 5.3499e-01],\n",
       "          [1.4032e+00, 0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 5.6063e-01, 0.0000e+00],\n",
       "          [2.6047e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [2.2013e+00, 1.1386e+00, 9.8465e-01]],\n",
       "\n",
       "         [[4.1519e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [1.2409e+00, 0.0000e+00, 5.3015e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 2.0002e+00]]]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "652a779b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.06799927e+00, 2.44573490e+00],\n",
       "         [1.73928662e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00, 1.00718015e+00, 5.93799170e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 3.28226371e+00],\n",
       "         [0.00000000e+00, 7.59423110e-02, 0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00, 9.79121084e-01, 1.24027071e+00],\n",
       "         [1.10261660e+00, 0.00000000e+00, 2.43618940e+00],\n",
       "         [2.30878200e-01, 1.98811368e-01, 0.00000000e+00]],\n",
       "\n",
       "        [[2.94290854e-01, 1.45152606e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 9.89254821e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.18120716e+00]],\n",
       "\n",
       "        [[0.00000000e+00, 0.00000000e+00, 1.63367536e+00],\n",
       "         [1.29421567e+00, 0.00000000e+00, 1.50304063e+00],\n",
       "         [1.32579594e+00, 0.00000000e+00, 5.01186946e-01]],\n",
       "\n",
       "        [[0.00000000e+00, 1.92422255e+00, 4.36245840e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 3.80317860e-02]],\n",
       "\n",
       "        [[0.00000000e+00, 3.25027391e-01, 1.39699099e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 7.37268771e-02],\n",
       "         [0.00000000e+00, 4.41263873e-01, 0.00000000e+00]],\n",
       "\n",
       "        [[7.68220987e-01, 1.29880623e+00, 8.90879865e-01],\n",
       "         [9.44938293e-01, 2.97539939e-01, 0.00000000e+00],\n",
       "         [3.95265692e-01, 7.94407500e-01, 6.94037528e-02]]],\n",
       "\n",
       "\n",
       "       [[[5.13679623e-01, 0.00000000e+00, 4.09398950e-01],\n",
       "         [6.23551957e-01, 0.00000000e+00, 1.56369343e+00],\n",
       "         [4.74044540e-01, 0.00000000e+00, 1.62281343e+00]],\n",
       "\n",
       "        [[0.00000000e+00, 8.15421333e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.26371948e+00],\n",
       "         [0.00000000e+00, 1.38608394e+00, 9.87152132e-02]],\n",
       "\n",
       "        [[3.88110684e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.53607473e-01, 4.60412215e-01],\n",
       "         [0.00000000e+00, 2.25092082e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00, 2.85300314e-01, 0.00000000e+00],\n",
       "         [1.22238200e+00, 2.69319443e-01, 0.00000000e+00],\n",
       "         [2.74463097e+00, 0.00000000e+00, 1.89927824e+00]],\n",
       "\n",
       "        [[0.00000000e+00, 0.00000000e+00, 1.08551472e+00],\n",
       "         [6.93572365e-01, 0.00000000e+00, 1.40134627e+00],\n",
       "         [0.00000000e+00, 1.09606620e+00, 8.10224930e-01]],\n",
       "\n",
       "        [[0.00000000e+00, 3.25089698e+00, 0.00000000e+00],\n",
       "         [3.34825747e-02, 1.25202143e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 2.31898389e-01, 2.78633955e-01]],\n",
       "\n",
       "        [[0.00000000e+00, 3.88432318e+00, 0.00000000e+00],\n",
       "         [6.11468312e-01, 0.00000000e+00, 1.27584141e+00],\n",
       "         [8.75474990e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[3.57831548e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [1.40895625e+00, 0.00000000e+00, 9.08392208e-01],\n",
       "         [0.00000000e+00, 7.66615565e-01, 3.14744737e+00]]],\n",
       "\n",
       "\n",
       "       [[[0.00000000e+00, 1.11005187e+00, 0.00000000e+00],\n",
       "         [6.00338385e-01, 0.00000000e+00, 1.26441512e+00],\n",
       "         [0.00000000e+00, 1.07592743e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00, 7.65679657e-01, 1.87992588e-02],\n",
       "         [3.05615005e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [1.61702956e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[4.49134995e-02, 4.61295532e-01, 2.33576518e-01],\n",
       "         [1.80013440e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[1.07080481e+00, 0.00000000e+00, 1.13445149e-01],\n",
       "         [0.00000000e+00, 2.44446122e-01, 2.68342836e-01],\n",
       "         [6.22341029e-01, 8.79913048e-01, 1.63638957e+00]],\n",
       "\n",
       "        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [1.71854027e-01, 0.00000000e+00, 1.63590070e+00],\n",
       "         [0.00000000e+00, 2.08983650e-01, 0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [1.11237558e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [3.02651884e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00, 3.49260801e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [4.55774288e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00, 0.00000000e+00, 1.27336711e+00],\n",
       "         [5.15134832e-01, 2.82916324e-01, 4.84819939e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]],\n",
       "\n",
       "\n",
       "       [[[0.00000000e+00, 1.09687485e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 2.05721646e+00],\n",
       "         [0.00000000e+00, 2.47403162e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00, 8.12972661e-01, 1.43623835e-01],\n",
       "         [7.52548730e-01, 7.24792411e-02, 6.75544773e-01],\n",
       "         [1.00861793e+00, 2.31727439e+00, 3.07531217e-01]],\n",
       "\n",
       "        [[0.00000000e+00, 1.44790236e+00, 2.08057540e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [1.41697789e+00, 3.60697877e-01, 0.00000000e+00]],\n",
       "\n",
       "        [[1.14414618e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [1.56708055e+00, 1.08258780e+00, 4.96098814e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 7.51769389e-01]],\n",
       "\n",
       "        [[0.00000000e+00, 4.92608376e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 6.25940592e-02, 2.10489747e+00],\n",
       "         [1.49134210e-01, 1.63932283e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [4.77672235e+00, 1.83588736e+00, 0.00000000e+00],\n",
       "         [1.03603763e+00, 0.00000000e+00, 1.80118660e+00]],\n",
       "\n",
       "        [[0.00000000e+00, 5.39827135e-01, 3.83282759e-01],\n",
       "         [2.34205172e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [9.27430051e-01, 1.14536859e+00, 1.05938268e+00]],\n",
       "\n",
       "        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 5.81962128e-01, 1.56031655e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]],\n",
       "\n",
       "\n",
       "       [[[2.56343482e-01, 3.29002186e+00, 5.11217655e-01],\n",
       "         [0.00000000e+00, 7.55195879e-01, 0.00000000e+00],\n",
       "         [1.78496252e+00, 1.91510335e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00, 2.96123014e+00, 0.00000000e+00],\n",
       "         [1.48435247e+00, 0.00000000e+00, 2.02379817e-01],\n",
       "         [0.00000000e+00, 2.12580495e+00, 2.60972372e-03]],\n",
       "\n",
       "        [[0.00000000e+00, 1.46788291e+00, 1.00349254e+00],\n",
       "         [1.32212841e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [3.57858802e-01, 0.00000000e+00, 5.74359699e-01]],\n",
       "\n",
       "        [[1.13644203e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 2.27742812e+00, 1.67957452e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[1.12352543e+00, 3.09502305e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.03372153e+00, 0.00000000e+00],\n",
       "         [3.75538526e-02, 7.05378509e-01, 0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [2.22410925e+00, 0.00000000e+00, 9.59284703e-01],\n",
       "         [0.00000000e+00, 2.08646640e-01, 0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00, 0.00000000e+00, 4.90247898e-01],\n",
       "         [2.05671075e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 4.06832935e-01, 1.23994177e+00]],\n",
       "\n",
       "        [[7.20254018e-01, 2.30360007e+00, 8.85980561e-02],\n",
       "         [0.00000000e+00, 1.78473243e+00, 5.44719964e-01],\n",
       "         [9.84955520e-01, 8.49022106e-01, 0.00000000e+00]]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4f96846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output all close: False\n",
      "input gradients all close: False\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2048,10) (10,2048) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\SystemPoint\\Documents\\GitHub\\DNN_course_ITMO_2022\\lab1\\numpy_CNN\\module_tests.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/SystemPoint/Documents/GitHub/DNN_course_ITMO_2022/lab1/numpy_CNN/module_tests.ipynb#X21sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39moutput all close:\u001b[39m\u001b[39m\"\u001b[39m, np\u001b[39m.\u001b[39mallclose(my_out, torch_out_np, atol\u001b[39m=\u001b[39matol))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/SystemPoint/Documents/GitHub/DNN_course_ITMO_2022/lab1/numpy_CNN/module_tests.ipynb#X21sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39minput gradients all close:\u001b[39m\u001b[39m\"\u001b[39m, np\u001b[39m.\u001b[39mallclose(my_input_g, torch_input_g, atol\u001b[39m=\u001b[39matol))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/SystemPoint/Documents/GitHub/DNN_course_ITMO_2022/lab1/numpy_CNN/module_tests.ipynb#X21sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mfc weights gradients all close:\u001b[39m\u001b[39m\"\u001b[39m, np\u001b[39m.\u001b[39;49mallclose(my_resnet\u001b[39m.\u001b[39;49mfc\u001b[39m.\u001b[39;49mweights_gradient, torch_resnet\u001b[39m.\u001b[39;49mfc\u001b[39m.\u001b[39;49mweight\u001b[39m.\u001b[39;49mgrad\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39;49mnumpy(), atol\u001b[39m=\u001b[39;49matol))\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mallclose\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\SystemPoint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\numeric.py:2265\u001b[0m, in \u001b[0;36mallclose\u001b[1;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[0;32m   2194\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_allclose_dispatcher)\n\u001b[0;32m   2195\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mallclose\u001b[39m(a, b, rtol\u001b[39m=\u001b[39m\u001b[39m1.e-5\u001b[39m, atol\u001b[39m=\u001b[39m\u001b[39m1.e-8\u001b[39m, equal_nan\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m   2196\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2197\u001b[0m \u001b[39m    Returns True if two arrays are element-wise equal within a tolerance.\u001b[39;00m\n\u001b[0;32m   2198\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2263\u001b[0m \n\u001b[0;32m   2264\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2265\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mall\u001b[39m(isclose(a, b, rtol\u001b[39m=\u001b[39;49mrtol, atol\u001b[39m=\u001b[39;49matol, equal_nan\u001b[39m=\u001b[39;49mequal_nan))\n\u001b[0;32m   2266\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(res)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36misclose\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\SystemPoint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\numeric.py:2375\u001b[0m, in \u001b[0;36misclose\u001b[1;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[0;32m   2373\u001b[0m yfin \u001b[39m=\u001b[39m isfinite(y)\n\u001b[0;32m   2374\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(xfin) \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(yfin):\n\u001b[1;32m-> 2375\u001b[0m     \u001b[39mreturn\u001b[39;00m within_tol(x, y, atol, rtol)\n\u001b[0;32m   2376\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2377\u001b[0m     finite \u001b[39m=\u001b[39m xfin \u001b[39m&\u001b[39m yfin\n",
      "File \u001b[1;32mc:\\Users\\SystemPoint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\numeric.py:2356\u001b[0m, in \u001b[0;36misclose.<locals>.within_tol\u001b[1;34m(x, y, atol, rtol)\u001b[0m\n\u001b[0;32m   2354\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwithin_tol\u001b[39m(x, y, atol, rtol):\n\u001b[0;32m   2355\u001b[0m     \u001b[39mwith\u001b[39;00m errstate(invalid\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m-> 2356\u001b[0m         \u001b[39mreturn\u001b[39;00m less_equal(\u001b[39mabs\u001b[39m(x\u001b[39m-\u001b[39;49my), atol \u001b[39m+\u001b[39m rtol \u001b[39m*\u001b[39m \u001b[39mabs\u001b[39m(y))\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2048,10) (10,2048) "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "resnet 101 test\n",
    "\"\"\"\n",
    "\n",
    "batch_size = 10\n",
    "height = width = 32\n",
    "n_channels = 1\n",
    "\n",
    "input_data = np.random.rand(batch_size, n_channels, height, width).astype(np.float32)\n",
    "input_data_torch = torch.from_numpy(input_data).float()\n",
    "input_data_torch.requires_grad = True\n",
    "output_gradient = np.random.rand(batch_size, 10).astype(np.float32)\n",
    "\n",
    "torch_resnet = resnet101_torch(10, 1)\n",
    "torch_resnet.eval()\n",
    "my_resnet = resnet101(10, 1)\n",
    "my_resnet.eval()\n",
    "\n",
    "my_resnet.clone_weights_from_torch(torch_resnet)\n",
    "\n",
    "my_out = my_resnet.forward(input_data)\n",
    "\n",
    "torch_out = torch_resnet(input_data_torch)\n",
    "torch_out_np = torch_out.detach().numpy()\n",
    "\n",
    "torch_out.backward(torch.tensor(output_gradient), retain_graph=True)\n",
    "torch_input_g = input_data_torch.grad.detach().numpy()\n",
    "\n",
    "my_input_g = my_resnet.backward(output_gradient)\n",
    "\n",
    "atol=1e-3\n",
    "\n",
    "print(\"output all close:\", np.allclose(my_out, torch_out_np, atol=atol))\n",
    "print(\"input gradients all close:\", np.allclose(my_input_g, torch_input_g, atol=atol))\n",
    "\n",
    "print(\"fc weights gradients all close:\", np.allclose(my_resnet.fc.weights_gradient, torch_resnet.fc.weight.grad.detach().numpy(), atol=atol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14fb02cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output all close: True\n",
      "input gradients all close: True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "conv1 test\n",
    "\"\"\"\n",
    "\n",
    "batch_size = 10\n",
    "height = width = 32\n",
    "n_channels = 1\n",
    "\n",
    "input_data = np.random.rand(batch_size, n_channels, height, width).astype(np.float32)\n",
    "input_data_torch = torch.from_numpy(input_data).float()\n",
    "input_data_torch.requires_grad = True\n",
    "output_gradient = np.random.rand(batch_size, 64, 16, 16).astype(np.float32)\n",
    "\n",
    "torch_resnet = resnet101_torch(10, 1)\n",
    "torch_resnet.eval()\n",
    "my_resnet = resnet101(10, 1)\n",
    "my_resnet.eval()\n",
    "\n",
    "my_resnet.clone_weights_from_torch(torch_resnet)\n",
    "\n",
    "my_out = my_resnet.conv1.forward(input_data)\n",
    "\n",
    "torch_out = torch_resnet.conv1(input_data_torch)\n",
    "torch_out_np = torch_out.detach().numpy()\n",
    "\n",
    "torch_out.backward(torch.tensor(output_gradient), retain_graph=True)\n",
    "torch_input_g = input_data_torch.grad.detach().numpy()\n",
    "\n",
    "my_input_g = my_resnet.conv1.backward(output_gradient)\n",
    "\n",
    "atol=1e-3\n",
    "\n",
    "print(\"output all close:\", np.allclose(my_out, torch_out_np, atol=atol))\n",
    "print(\"input gradients all close:\", np.allclose(my_input_g, torch_input_g, atol=atol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57fc2d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output all close: False\n",
      "input gradients all close: False\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "conv2_x test\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "batch_size = 10\n",
    "height = width = 8\n",
    "n_channels = 64\n",
    "\n",
    "input_data = np.random.rand(batch_size, n_channels, height, width).astype(np.float32)\n",
    "input_data_torch = torch.from_numpy(input_data).float()\n",
    "input_data_torch.requires_grad = True\n",
    "output_gradient = np.random.rand(batch_size, 256, 8, 8).astype(np.float32)\n",
    "\n",
    "torch_resnet = resnet101_torch(10, 1)\n",
    "torch_resnet.eval()\n",
    "my_resnet = resnet101(10, 1)\n",
    "my_resnet.eval()\n",
    "\n",
    "my_resnet.clone_weights_from_torch(torch_resnet)\n",
    "\n",
    "my_out = my_resnet.conv2_x.forward(input_data)\n",
    "\n",
    "torch_out = torch_resnet.conv2_x(input_data_torch)\n",
    "torch_out_np = torch_out.detach().numpy()\n",
    "\n",
    "torch_out.backward(torch.tensor(output_gradient), retain_graph=True)\n",
    "torch_input_g = input_data_torch.grad.detach().numpy()\n",
    "\n",
    "my_input_g = my_resnet.conv2_x.backward(output_gradient)\n",
    "\n",
    "atol=1e-3\n",
    "\n",
    "print(\"output all close:\", np.allclose(my_out, torch_out_np, atol=atol))\n",
    "print(\"input gradients all close:\", np.allclose(my_input_g, torch_input_g, atol=atol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9234786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# conv3_x test\n",
    "# \"\"\"\n",
    "\n",
    "# batch_size = 10\n",
    "# height = width = 8\n",
    "# n_channels = 256\n",
    "\n",
    "# input_data = np.random.rand(batch_size, n_channels, height, width).astype(np.float32)\n",
    "# input_data_torch = torch.from_numpy(input_data).float()\n",
    "# input_data_torch.requires_grad = True\n",
    "# output_gradient = np.random.rand(batch_size, 512, 4, 4).astype(np.float32)\n",
    "\n",
    "# torch_resnet = resnet101_torch(10, 1)\n",
    "# my_resnet = resnet101(10, 1)\n",
    "\n",
    "# my_resnet.clone_weights_from_torch(torch_resnet)\n",
    "\n",
    "# my_out = my_resnet.conv3_x.forward(input_data)\n",
    "\n",
    "# torch_out = torch_resnet.conv3_x(input_data_torch)\n",
    "# torch_out_np = torch_out.detach().numpy()\n",
    "\n",
    "# torch_out.backward(torch.tensor(output_gradient), retain_graph=True)\n",
    "# torch_input_g = input_data_torch.grad.detach().numpy()\n",
    "\n",
    "# my_input_g = my_resnet.conv3_x.backward(output_gradient)\n",
    "\n",
    "# atol=1e-3\n",
    "\n",
    "# print(\"output all close:\", np.allclose(my_out, torch_out_np, atol=atol))\n",
    "# print(\"input gradients all close:\", np.allclose(my_input_g, torch_input_g, atol=atol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c31786ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# conv4_x test\n",
    "# \"\"\"\n",
    "\n",
    "# batch_size = 10\n",
    "# height = width = 4\n",
    "# n_channels = 512\n",
    "\n",
    "# input_data = np.random.rand(batch_size, n_channels, height, width).astype(np.float32)\n",
    "# input_data_torch = torch.from_numpy(input_data).float()\n",
    "# input_data_torch.requires_grad = True\n",
    "# output_gradient = np.random.rand(batch_size, 1024, 2, 2).astype(np.float32)\n",
    "\n",
    "# torch_resnet = resnet101_torch(10, 1)\n",
    "# my_resnet = resnet101(10, 1)\n",
    "\n",
    "# my_resnet.clone_weights_from_torch(torch_resnet)\n",
    "\n",
    "# my_out = my_resnet.conv4_x.forward(input_data)\n",
    "\n",
    "# torch_out = torch_resnet.conv4_x(input_data_torch)\n",
    "# torch_out_np = torch_out.detach().numpy()\n",
    "\n",
    "# torch_out.backward(torch.tensor(output_gradient), retain_graph=True)\n",
    "# torch_input_g = input_data_torch.grad.detach().numpy()\n",
    "\n",
    "# my_input_g = my_resnet.conv4_x.backward(output_gradient)\n",
    "\n",
    "# atol=1e-3\n",
    "\n",
    "# print(\"output all close:\", np.allclose(my_out, torch_out_np, atol=atol))\n",
    "# print(\"input gradients all close:\", np.allclose(my_input_g, torch_input_g, atol=atol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b704ef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# conv5_x test\n",
    "# \"\"\"\n",
    "\n",
    "# batch_size = 10\n",
    "# height = width = 2\n",
    "# n_channels = 1024\n",
    "\n",
    "# input_data = np.random.rand(batch_size, n_channels, height, width).astype(np.float32)\n",
    "# input_data_torch = torch.from_numpy(input_data).float()\n",
    "# input_data_torch.requires_grad = True\n",
    "# output_gradient = np.random.rand(batch_size, 2048, 1, 1).astype(np.float32)\n",
    "\n",
    "# torch_resnet = resnet101_torch(10, 1)\n",
    "# my_resnet = resnet101(10, 1)\n",
    "\n",
    "# my_resnet.clone_weights_from_torch(torch_resnet)\n",
    "\n",
    "# my_out = my_resnet.conv5_x.forward(input_data)\n",
    "\n",
    "# torch_out = torch_resnet.conv5_x(input_data_torch)\n",
    "# torch_out_np = torch_out.detach().numpy()\n",
    "\n",
    "# torch_out.backward(torch.tensor(output_gradient), retain_graph=True)\n",
    "# torch_input_g = input_data_torch.grad.detach().numpy()\n",
    "\n",
    "# my_input_g = my_resnet.conv5_x.backward(output_gradient)\n",
    "\n",
    "# atol=1e-3\n",
    "\n",
    "# print(\"output all close:\", np.allclose(my_out, torch_out_np, atol=atol))\n",
    "# print(\"input gradients all close:\", np.allclose(my_input_g, torch_input_g, atol=atol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "affa6502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# AdamOptimizer test\n",
    "# \"\"\"\n",
    "\n",
    "# from torch.optim import Adam as Adam_torch\n",
    "\n",
    "# n_input_features = 6\n",
    "# n_output_features = 3\n",
    "# batch_size = 5\n",
    "# input_data = np.random.rand(batch_size, n_input_features).astype(np.float32)\n",
    "# input_data_torch = torch.from_numpy(input_data).float()\n",
    "# input_data_torch.requires_grad = True\n",
    "# output_gradient = np.random.rand(batch_size, n_output_features).astype(np.float32)\n",
    "\n",
    "# torch_fc = torch.nn.Linear(n_input_features, n_output_features)\n",
    "# torch_out = torch_fc(input_data_torch)\n",
    "# torch_out_np = torch_out.detach().numpy()\n",
    "# torch_out.backward(torch.tensor(output_gradient), retain_graph=True)\n",
    "# torch_wg = torch_fc.weight.grad.detach().numpy().T\n",
    "# torch_bg = torch_fc.bias.grad.detach().numpy().reshape(-1, 1).T\n",
    "# torch_input_g = input_data_torch.grad.detach().numpy()\n",
    "\n",
    "\n",
    "# my_fc = FullyConnectedLayer(n_input_features, n_output_features)\n",
    "# my_fc.weights = torch_fc.weight.detach().numpy().T\n",
    "# my_fc.bias = torch_fc.bias.detach().numpy().reshape(-1, 1).T\n",
    "# my_out = my_fc.forward(input_data)\n",
    "# my_input_g = my_fc.backward(output_gradient)\n",
    "# my_wg = my_fc.weights_gradient\n",
    "# my_bg = my_fc.bias_gradient\n",
    "\n",
    "# atol=1e-3\n",
    "\n",
    "# print(\"output all close:\", np.allclose(my_out, torch_out_np, atol=atol))\n",
    "# print(\"input gradients all close:\", np.allclose(my_input_g, torch_input_g, atol=atol))\n",
    "# print(\"before adam weights gradients all close:\", np.allclose(my_wg, torch_wg, atol=atol))\n",
    "# print(\"before adam bias gradients all close:\", np.allclose(my_bg, torch_bg, atol=atol))\n",
    "# print(my_wg, \"\\n\", torch_wg)\n",
    "\n",
    "# my_adam = AdamOptimizer(my_fc.get_trainable_layers(), 0.001, 0.9, 0.999, 1e-8)\n",
    "# my_adam.step()\n",
    "\n",
    "# torch_adam = Adam_torch(torch_fc.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-8)\n",
    "# torch_adam.step()\n",
    "\n",
    "# print(\"after adam weights gradients all close:\", np.allclose(my_fc.weights_gradient, torch_fc.weight.grad.detach().numpy().T, atol=atol))\n",
    "# print(\"after adam bias gradients all close:\", np.allclose(my_fc.bias_gradient, torch_fc.bias.grad.detach().numpy().reshape(-1, 1).T, atol=atol))\n",
    "# print(my_fc.weights_gradient, \"\\n\", torch_fc.weight.grad.detach().numpy().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e7675aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output all close: True\n",
      "input gradients all close: True\n",
      "weights gradients all close: True\n",
      "bias gradients all close: True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "BatchNorm test\n",
    "\"\"\"\n",
    "\n",
    "batch_size = 4\n",
    "n_channels = 5\n",
    "height = 8\n",
    "width = 8\n",
    "\n",
    "input_data = np.random.rand(batch_size, n_channels, height, width).astype(np.float32)\n",
    "input_data_torch = torch.from_numpy(input_data).float()\n",
    "input_data_torch.requires_grad = True\n",
    "output_gradient = np.random.rand(batch_size, n_channels, height, width).astype(np.float32)\n",
    "\n",
    "torch_bn = torch.nn.BatchNorm2d(n_channels, momentum=1)\n",
    "\n",
    "my_bn = BatchNormalization2d(n_channels)\n",
    "\n",
    "my_bn.gamma = torch_bn.weight.detach().numpy().reshape(1, n_channels, 1, 1)\n",
    "my_bn.beta = torch_bn.bias.detach().numpy().reshape(1, n_channels, 1, 1)\n",
    "\n",
    "my_bn.mean = torch_bn.running_mean.detach().numpy().reshape(1, n_channels, 1, 1)\n",
    "my_bn.var = torch_bn.running_var.detach().numpy().reshape(1, n_channels, 1, 1)\n",
    "\n",
    "my_out = my_bn.forward(input_data)\n",
    "\n",
    "torch_out = torch_bn(input_data_torch)\n",
    "\n",
    "torch_out_np = torch_out.detach().numpy()\n",
    "\n",
    "torch_out.backward(torch.tensor(output_gradient), retain_graph=True)\n",
    "\n",
    "torch_input_g = input_data_torch.grad.detach().numpy()\n",
    "\n",
    "my_input_g = my_bn.backward(output_gradient)\n",
    "\n",
    "atol=1e-2\n",
    "\n",
    "print(\"output all close:\", np.allclose(my_out, torch_out_np, atol=atol))\n",
    "print(\"input gradients all close:\", np.allclose(my_input_g, torch_input_g, atol=atol))\n",
    "print(\"weights gradients all close:\", np.allclose(my_bn.gamma_gradient, torch_bn.weight.grad.detach().numpy().reshape(1, n_channels, 1, 1), atol=atol))\n",
    "print(\"bias gradients all close:\", np.allclose(my_bn.beta_gradient, torch_bn.bias.grad.detach().numpy().reshape(1, n_channels, 1, 1), atol=atol))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bca9fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 1\n",
      "my_conv forward time: 0.33388376235961914\n",
      "my_conv_with_loops forward time: 2.353210210800171\n",
      "torch_conv forward time: 0.08339810371398926\n",
      "my_conv fully matrix multiplication: 0.28624987602233887\n",
      "my_conv semi_matrix_backward time: 1.4046761989593506\n",
      "my_conv_with_loops backward time: 2.42439603805542\n",
      "torch_conv backward time: 0.15736699104309082\n",
      "batch_size: 2\n",
      "my_conv forward time: 0.5330967903137207\n",
      "my_conv_with_loops forward time: 2.108637809753418\n",
      "torch_conv forward time: 0.16659021377563477\n",
      "my_conv fully matrix multiplication: 0.4738328456878662\n",
      "my_conv semi_matrix_backward time: 2.6497817039489746\n",
      "my_conv_with_loops backward time: 4.740177631378174\n",
      "torch_conv backward time: 0.3679213523864746\n",
      "batch_size: 4\n",
      "my_conv forward time: 1.0229949951171875\n",
      "my_conv_with_loops forward time: 2.224562644958496\n",
      "torch_conv forward time: 0.1580660343170166\n",
      "my_conv fully matrix multiplication: 0.8497607707977295\n",
      "my_conv semi_matrix_backward time: 5.198260545730591\n",
      "my_conv_with_loops backward time: 9.5380277633667\n",
      "torch_conv backward time: 0.37662506103515625\n",
      "batch_size: 8\n",
      "my_conv forward time: 1.939718246459961\n",
      "my_conv_with_loops forward time: 2.3732821941375732\n",
      "torch_conv forward time: 0.17607378959655762\n",
      "my_conv fully matrix multiplication: 1.6494240760803223\n",
      "my_conv semi_matrix_backward time: 10.129782915115356\n",
      "my_conv_with_loops backward time: 18.280099391937256\n",
      "torch_conv backward time: 0.5119674205780029\n",
      "batch_size: 16\n",
      "my_conv forward time: 3.8003203868865967\n",
      "my_conv_with_loops forward time: 3.2648208141326904\n",
      "torch_conv forward time: 0.24799227714538574\n",
      "my_conv fully matrix multiplication: 3.595266103744507\n",
      "my_conv semi_matrix_backward time: 21.00715708732605\n",
      "my_conv_with_loops backward time: 41.56549143791199\n",
      "torch_conv backward time: 0.45488643646240234\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Conv2d vs Conv2dWithLoops vs torch.nn.Conv2d time comparison forward and backward\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "\n",
    "n_input_channels = 4\n",
    "n_output_channels = 2\n",
    "width = 3\n",
    "height = 5\n",
    "\n",
    "kernel_size = 3\n",
    "stride = 1\n",
    "padding = 3\n",
    "\n",
    "output_width = (width + 2 * padding - kernel_size) // stride + 1\n",
    "output_height = (height + 2 * padding - kernel_size) // stride + 1\n",
    "\n",
    "for batch_size in [1, 2, 4, 8, 16]:\n",
    "    print(\"batch_size:\", batch_size)\n",
    "\n",
    "    input_data = np.random.rand(batch_size, n_input_channels, height, width).astype(np.float32)\n",
    "    input_data_torch = torch.from_numpy(input_data).float()\n",
    "    input_data_torch.requires_grad = True\n",
    "    output_gradient = np.random.rand(batch_size, n_output_channels, output_height, output_width).astype(np.float32)\n",
    "\n",
    "    torch_conv = torch.nn.Conv2d(n_input_channels, n_output_channels, kernel_size, stride, padding)\n",
    "\n",
    "    my_conv_with_loops = Conv2dWithLoops(n_input_channels, n_output_channels, kernel_size, stride, padding)\n",
    "    my_conv_with_loops.weights = torch_conv.weight.detach().numpy()\n",
    "\n",
    "    my_conv = Conv2d(n_input_channels, n_output_channels, kernel_size, stride, padding)\n",
    "    my_conv.weights = torch_conv.weight.detach().numpy()\n",
    "\n",
    "    n_iterations = 1000\n",
    "\n",
    "    start = time.time()\n",
    "    for i in range(n_iterations):\n",
    "        my_out = my_conv.forward(input_data)\n",
    "    end = time.time()\n",
    "    print(f\"my_conv forward time: {end - start}\")\n",
    "\n",
    "    start = time.time()\n",
    "    for i in range(n_iterations):\n",
    "        my_out_with_loops = my_conv_with_loops.forward(input_data)\n",
    "    end = time.time()\n",
    "    print(f\"my_conv_with_loops forward time: {end - start}\")\n",
    "\n",
    "    start = time.time()\n",
    "    for i in range(n_iterations):\n",
    "        torch_out = torch_conv(input_data_torch)\n",
    "    end = time.time()\n",
    "    print(f\"torch_conv forward time: {end - start}\")\n",
    "\n",
    "    start = time.time()\n",
    "    for i in range(n_iterations):\n",
    "        my_input_g = my_conv.backward_as_matrix_multiplication(output_gradient)\n",
    "    end = time.time()\n",
    "    print(f\"my_conv fully matrix multiplication: {end - start}\")\n",
    "\n",
    "    start = time.time()\n",
    "    for i in range(n_iterations):\n",
    "        my_input_g = my_conv.semi_matrix_backward(output_gradient)\n",
    "    end = time.time()\n",
    "    print(f\"my_conv semi_matrix_backward time: {end - start}\")\n",
    "\n",
    "    start = time.time()\n",
    "    for i in range(n_iterations):\n",
    "        my_input_g_with_loops = my_conv_with_loops.backward(output_gradient)\n",
    "    end = time.time()\n",
    "    print(f\"my_conv_with_loops backward time: {end - start}\")\n",
    "\n",
    "    start = time.time()\n",
    "    for i in range(n_iterations):\n",
    "        torch_out.backward(torch.tensor(output_gradient), retain_graph=True)\n",
    "    end = time.time()\n",
    "    print(f\"torch_conv backward time: {end - start}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "2bbf79ea567ebf64b92b9cf68f2b08a0cf8db5ff8a7f29f56d99d802810464d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
